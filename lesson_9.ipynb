{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtyomShabunin/SMOPA-25/blob/main/lesson_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eLOjhZ6rm3Ao",
      "metadata": {
        "id": "eLOjhZ6rm3Ao"
      },
      "source": [
        "<img src=\"https://prana-system.com/files/110/rds_color_full.png\" alt=\"tot image\" width=\"300\"  align=\"center\"/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src=\"https://mpei.ru/AboutUniverse/OficialInfo/Attributes/PublishingImages/logo1.jpg\" alt=\"mpei image\" width=\"200\" align=\"center\"/>\n",
        "<img src=\"https://mpei.ru/Structure/Universe/tanpe/structure/tfhe/PublishingImages/tot.png\" alt=\"tot image\" width=\"100\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "# **Системы машинного обучения и предиктивной аналитики в тепловой и возобновляемой энергетике**  \n",
        "\n",
        "# ***Практические занятия***\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1008c8a1-596c-48b9-a100-66e0866eebfa",
      "metadata": {
        "id": "1008c8a1-596c-48b9-a100-66e0866eebfa"
      },
      "source": [
        "# Занятие №9\n",
        "# Прогнозирование временных рядов методами глубокого обучения\n",
        "**14 апреля 2025г.**\n",
        "\n",
        "---\n",
        "\n",
        "Задачу прогнозирования временных рядов можно эффективно решать методами глубокого обучения, особенно когда данные содержат нелинейные зависимости, сезонность или сложную динамику. Основные подходы и архитектуры, которые используются:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Рекуррентные нейронные сети (RNN)**\n",
        "Используются для последовательной обработки данных.\n",
        "\n",
        "- **Vanilla RNN** — базовая форма RNN, редко используется из-за проблем исчезающего градиента.\n",
        "- **LSTM (Long Short-Term Memory)** — популярный выбор, хорошо справляется с долговременными зависимостями.\n",
        "- **GRU (Gated Recurrent Unit)** — упрощённая версия LSTM, быстрее обучается и требует меньше вычислений.\n",
        "\n",
        "**Пример использования:**  \n",
        "Вход: последовательность значений временного ряда  \n",
        "Выход: значение (или несколько) на следующем шаге  \n",
        "\n",
        "---\n",
        "\n",
        "### 2. **1D-Сверточные сети (CNN для временных рядов)**\n",
        "Могут извлекать локальные шаблоны в данных.\n",
        "\n",
        "- Эффективны для коротких зависимостей и быстрых расчётов.\n",
        "- Часто используются в комбинации с RNN/LSTM (например, CNN+LSTM).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Encoder-Decoder архитектуры**\n",
        "Подход из области машинного перевода, адаптированный к временным рядам:\n",
        "\n",
        "- **Encoder** считывает входную последовательность.\n",
        "- **Decoder** генерирует выходную последовательность (будущие значения).\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Transformer и его модификации**\n",
        "Модель, изначально разработанная для NLP, показала себя отлично и в задаче прогнозирования временных рядов.\n",
        "\n",
        "- **Informer, Autoformer, Transformer-XL, TimesNet** — специализированные архитектуры для временных рядов.\n",
        "- Transformer позволяет учитывать долгосрочные зависимости благодаря механизмам внимания.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Сети прямого распространения (MLP)**\n",
        "Простые полносвязные сети можно применять, если на вход подаются фичи из скользящего окна (например, 10 предыдущих точек). Хорошо работают при небольшой сложности данных.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Гибридные подходы**\n",
        "Комбинации из разных типов сетей:\n",
        "- **CNN+LSTM**\n",
        "- **Encoder (CNN/LSTM) + Attention + Decoder**\n",
        "- **Transformer + Residual MLP**\n",
        "\n",
        "---\n",
        "\n",
        "### Как строится вход для модели:\n",
        "- **Скользящее окно**: берём последние `n` точек временного ряда как вход, предсказываем следующие `m` точек.\n",
        "- Можно добавлять фичи:\n",
        "  - Временные метки (час, день недели, месяц)\n",
        "  - Внешние воздействия (управляющие сигналы, температура воздуха и т.д.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e0f550-b5f8-48de-8c47-6eaac025b22e",
      "metadata": {
        "id": "75e0f550-b5f8-48de-8c47-6eaac025b22e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\", rc={'figure.figsize':(15,6)})\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57kLvbsUeJ9F",
      "metadata": {
        "id": "57kLvbsUeJ9F"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# device = torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fad1c6-142f-44de-a686-75ad901a7c91",
      "metadata": {
        "id": "a1fad1c6-142f-44de-a686-75ad901a7c91"
      },
      "source": [
        "## Загрузка данных\n",
        "Набор содержит данные о почасовом производстве ветряной и солнечной электроэнергии (в МВт) во французской электросети с 2020 года."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xv9d5F6DoVtk",
      "metadata": {
        "id": "xv9d5F6DoVtk"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "gdown.download('https://drive.google.com/uc?id=1NAYPaEkovk7jvaURdjI0nCi7CUMxry7W', verify=False)\n",
        "\n",
        "df = pd.read_csv('./intermittent-renewables-production-france.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427ef601-6f9c-4037-baa9-7ec5acba46bb",
      "metadata": {
        "id": "427ef601-6f9c-4037-baa9-7ec5acba46bb"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('intermittent-renewables-production-france.csv')\n",
        "df = df.rename(columns={'Date and Hour' : 'DateTime'})\n",
        "df['DateTime'] = df['DateTime'].str.slice(stop=-6)\n",
        "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "df = df.sort_values(ascending=True,by='DateTime')\n",
        "df = df.drop(['Date','dayOfYear','dayName','monthName'],axis=1)\n",
        "df = df.dropna()\n",
        "df = df.set_index(\"DateTime\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33185446-6da7-4691-83e9-a7d8b7974ec2",
      "metadata": {
        "id": "33185446-6da7-4691-83e9-a7d8b7974ec2"
      },
      "outputs": [],
      "source": [
        "solar = df[df['Source'] == 'Solar']['Production']\n",
        "wind = df[df['Source'] == 'Wind']['Production']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c87b1e39-ef02-4f57-afaf-cd08e64d7fcf",
      "metadata": {
        "id": "c87b1e39-ef02-4f57-afaf-cd08e64d7fcf"
      },
      "outputs": [],
      "source": [
        "solar.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "--RCwM5nqRIs",
      "metadata": {
        "id": "--RCwM5nqRIs"
      },
      "outputs": [],
      "source": [
        "color_pal = sns.color_palette()\n",
        "solar.plot(style='.',\n",
        "          figsize=(20, 5),\n",
        "          ms=3,\n",
        "          color=color_pal[3],\n",
        "          title='Солнечная электроэнергия')\n",
        "plt.ylabel(\"МВт\")\n",
        "plt.show()\n",
        "\n",
        "# wind.plot(style='.',\n",
        "#           figsize=(20, 5),\n",
        "#           ms=3,\n",
        "#           color=color_pal[2],\n",
        "#           title='Ветряная электроэнергия')\n",
        "# plt.ylabel(\"МВт\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Bp1xDNbrfOL",
      "metadata": {
        "id": "4Bp1xDNbrfOL"
      },
      "source": [
        "## Сформируем датасет на основе данных о производстве солнечной электроэнергии\n",
        "### Разделим данные на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lz5cROvnqUiB",
      "metadata": {
        "id": "lz5cROvnqUiB"
      },
      "outputs": [],
      "source": [
        "cutoff_date = '2023-01-01'\n",
        "\n",
        "solar_train = solar[solar.index < cutoff_date].copy()\n",
        "solar_test = solar[solar.index >= cutoff_date].copy()\n",
        "\n",
        "print(f\"Train: {solar_train.shape[0]} записей\")\n",
        "print(f\"Test: {solar_test.shape[0]} записей\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kUveyOo8uUBf",
      "metadata": {
        "id": "kUveyOo8uUBf"
      },
      "source": [
        "### Нормализация или стандартизация данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nt0MamysqRUs",
      "metadata": {
        "id": "Nt0MamysqRUs"
      },
      "outputs": [],
      "source": [
        "solar_scaler = preprocessing.MinMaxScaler() # нормализация данных\n",
        "# solar_scaler = preprocessing.StandardScaler() # стандартизация данных\n",
        "\n",
        "solar_train_scaled = pd.DataFrame(\n",
        "    solar_scaler.fit_transform(solar_train.values[:, None]),\n",
        "    index=solar_train.index)\n",
        "\n",
        "solar_test_scaled = pd.DataFrame(\n",
        "    solar_scaler.transform(solar_test.values[:, None]),\n",
        "    index=solar_test.index)\n",
        "\n",
        "solar_train_scaled.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dIpr58H1KVG",
      "metadata": {
        "id": "9dIpr58H1KVG"
      },
      "source": [
        "### Dataset и DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kd70-LNr1u3D",
      "metadata": {
        "id": "kd70-LNr1u3D"
      },
      "source": [
        "<img src=\"https://github.com/ArtyomShabunin/SMOPA-25/blob/main/imgs/l9_fig1.png?raw=true\" alt=\"trend_seasonality\" width=\"800\"  align=\"center\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2fdfb90-5470-476e-9972-e2957cab8f6c",
      "metadata": {
        "id": "c2fdfb90-5470-476e-9972-e2957cab8f6c"
      },
      "outputs": [],
      "source": [
        "class SolarDataset(Dataset):\n",
        "    def __init__(self, data, n_lags, horizon):\n",
        "        self.n_lags = n_lags\n",
        "        self.horizon = horizon\n",
        "        data = data.reshape(-1)\n",
        "        self.x = torch.tensor(data[:-self.horizon], dtype=torch.float32)\n",
        "        self.y = torch.tensor(data[self.n_lags:],dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx:idx+self.n_lags], self.y[idx:idx+self.horizon]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y.shape[0]-self.horizon+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bc9bc9-793e-4305-b998-07ca49696197",
      "metadata": {
        "id": "87bc9bc9-793e-4305-b998-07ca49696197"
      },
      "outputs": [],
      "source": [
        "N_LAGS = 20\n",
        "HORIZON = 20\n",
        "\n",
        "solar_dataset = SolarDataset(solar_train_scaled.values, N_LAGS, HORIZON)\n",
        "print(f\"Размер датасета: {len(solar_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a8b295c-611a-4d15-9900-f4acbe89e1af",
      "metadata": {
        "id": "3a8b295c-611a-4d15-9900-f4acbe89e1af"
      },
      "outputs": [],
      "source": [
        "solar_train_size = int(0.8 * len(solar_dataset))\n",
        "solar_valid_size = len(solar_dataset) - solar_train_size\n",
        "\n",
        "solar_train_dataset = Subset(solar_dataset, range(solar_train_size))\n",
        "solar_valid_dataset = Subset(\n",
        "    solar_dataset, range(solar_train_size, solar_train_size + solar_valid_size))\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "solar_train_loader = DataLoader(solar_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "solar_valid_loader = DataLoader(solar_valid_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59ae886-5796-4548-b995-c190ec10e38a",
      "metadata": {
        "id": "a59ae886-5796-4548-b995-c190ec10e38a"
      },
      "source": [
        "## Предсказание производства солнечной электроэнергии\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h-f9N_9hkj3X",
      "metadata": {
        "id": "h-f9N_9hkj3X"
      },
      "source": [
        "Инициализируем переменные для дальнейшего сравнения моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AQLdm8kwkkMd",
      "metadata": {
        "id": "AQLdm8kwkkMd"
      },
      "outputs": [],
      "source": [
        "MAE_prediction = {}\n",
        "RMSE_prediction = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LpFFf7kUoU7n",
      "metadata": {
        "id": "LpFFf7kUoU7n"
      },
      "source": [
        "#### Функция для обучения моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445b6f98-e919-46be-9a60-e68633be9ff5",
      "metadata": {
        "id": "445b6f98-e919-46be-9a60-e68633be9ff5"
      },
      "outputs": [],
      "source": [
        "def train_model(model, loss_function, optimizer, scheduler, num_epochs=100):\n",
        "\n",
        "  loaders = {\"train\": solar_train_loader, \"valid\": solar_valid_loader}\n",
        "  losses = {\"train\": [], \"valid\": []}\n",
        "  lr = []\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    for k, dataloader in loaders.items():\n",
        "      running_loss = []\n",
        "\n",
        "      for x_batch, y_batch in dataloader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        if k == \"train\":\n",
        "          model.train()\n",
        "          optimizer.zero_grad()\n",
        "          out = model(x_batch, y_batch.shape[1])\n",
        "\n",
        "        else:\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            out = model(x_batch, y_batch.shape[1])\n",
        "\n",
        "        loss = loss_function(out, y_batch)\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "        if k == \"train\":\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      losses[k].append(np.array(running_loss).mean())\n",
        "    lr.append(scheduler.get_last_lr())\n",
        "    scheduler.step(losses[\"train\"][-1])\n",
        "\n",
        "  return model, losses, lr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vVYjbOwokiRJ",
      "metadata": {
        "id": "vVYjbOwokiRJ"
      },
      "source": [
        "### Полносвязная нейронная сеть (многослойный персептрон)\n",
        "\n",
        "Использование **полносвязной нейронной сети (fully connected neural network, FCNN или просто MLP — Multi-Layer Perceptron)** для задачи прогнозирования временного ряда имеет свои **преимущества и недостатки**, особенно по сравнению со специализированными архитектурами, такими как RNN, LSTM, GRU, CNN и Transformer.\n",
        "\n",
        "<img src=\"https://github.com/ArtyomShabunin/SMOPA-25/blob/main/imgs/FCNN%20for%20time%20series.png?raw=true\" alt=\"trend_seasonality\" width=\"500\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "**Преимущества полносвязной нейросети:**\n",
        "\n",
        "1. **Простота реализации**  \n",
        "   Полносвязная сеть — одна из самых простых архитектур. Не требует сложной подготовки данных, как, например, рекуррентные сети.\n",
        "\n",
        "2. **Быстрое обучение**  \n",
        "   За счёт отсутствия последовательных зависимостей обучение может быть быстрее, особенно на GPU.\n",
        "\n",
        "3. **Гибкость**  \n",
        "   Может моделировать нелинейные зависимости между входом и выходом при правильном выборе архитектуры и обучающих данных.\n",
        "\n",
        "4. **Параллельность**  \n",
        "   Обработка каждого входного примера может быть полностью параллелизирована, что ускоряет тренировку и предсказания.\n",
        "\n",
        "---\n",
        "\n",
        "**Недостатки:**\n",
        "\n",
        "1. **Игнорирование временной структуры**  \n",
        "   FCNN не обладает \"памятью\" и не учитывает порядок входных значений. Временные зависимости надо явно закодировать — например, подавать фиксированное окно прошлых значений.\n",
        "\n",
        "2. **Плохо обобщается на длинные зависимости**  \n",
        "   Если значимые события происходят далеко во времени, FCNN может не уловить эти долгосрочные связи.\n",
        "\n",
        "3. **Фиксированный входной размер**  \n",
        "   Нужно задавать длину временного окна (например, последние 10 шагов). Это ограничивает гибкость модели.\n",
        "\n",
        "4. **Сложность в учёте сезонности и трендов**  \n",
        "   В отличие от архитектур, специально предназначенных для анализа временных зависимостей (например, LSTM), FCNN хуже захватывает сезонные и трендовые паттерны, если они не явно выражены.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce3b70e-b7ee-426b-9c8b-67ac959208cf",
      "metadata": {
        "id": "cce3b70e-b7ee-426b-9c8b-67ac959208cf"
      },
      "outputs": [],
      "source": [
        "class FCNN(nn.Module):\n",
        "  def __init__(\n",
        "      self, input_size=N_LAGS, output_size=HORIZON, hidden_size=512, hidden_num=1):\n",
        "    super(FCNN, self).__init__()\n",
        "\n",
        "    # Входной слой\n",
        "    self.input_layer = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    # Скрытые слои\n",
        "    self.hidden_layers = nn.ModuleList()\n",
        "    for _ in range(hidden_num):\n",
        "        self.hidden_layers.append(\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_size, hidden_size),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Выходной слой\n",
        "    self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, horizon):\n",
        "    x = self.input_layer(x)\n",
        "\n",
        "    for layer in self.hidden_layers:\n",
        "        x = layer(x)\n",
        "\n",
        "    x = self.output_layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lOLexrMPpFF_",
      "metadata": {
        "id": "lOLexrMPpFF_"
      },
      "source": [
        "Инмциализация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf90ebf4-8d54-4a9c-ad58-342e55fd8e16",
      "metadata": {
        "id": "cf90ebf4-8d54-4a9c-ad58-342e55fd8e16"
      },
      "outputs": [],
      "source": [
        "HIDDEN_DIM = 64\n",
        "HIDDEN_NUM = 2\n",
        "\n",
        "FC_model = FCNN(\n",
        "    input_size=N_LAGS,\n",
        "    output_size=HORIZON,\n",
        "    hidden_size=HIDDEN_DIM,\n",
        "    hidden_num=HIDDEN_NUM).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(FC_model.parameters(), lr=0.01)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3,\n",
        "                                           patience=3, threshold=0.0001)\n",
        "\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q-KtVFxepJqS",
      "metadata": {
        "id": "q-KtVFxepJqS"
      },
      "source": [
        "Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "--qJBd0GMdCE",
      "metadata": {
        "id": "--qJBd0GMdCE"
      },
      "outputs": [],
      "source": [
        "FC_model, losses, lr = train_model(FC_model, loss_fn, optimizer, scheduler, num_epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79641d04-1130-49e5-9116-3bc4933f0951",
      "metadata": {
        "id": "79641d04-1130-49e5-9116-3bc4933f0951"
      },
      "outputs": [],
      "source": [
        "plt.plot(lr);\n",
        "plt.xlabel(\"Эпоха\");\n",
        "plt.ylabel(\"Коэффициент скорости обучения\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ab35c9-4e52-44fd-bd87-c090cf91178f",
      "metadata": {
        "id": "e5ab35c9-4e52-44fd-bd87-c090cf91178f"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses[\"train\"], label=\"Обучающая выборка\");\n",
        "plt.plot(losses[\"valid\"], label=\"Валидационная выборка\");\n",
        "plt.legend();\n",
        "plt.xlabel(\"Эпоха\");\n",
        "plt.ylabel(\"Среднеквадратичная ошибка\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98fd1870-72a5-4554-88eb-44d177ef1d3a",
      "metadata": {
        "id": "98fd1870-72a5-4554-88eb-44d177ef1d3a"
      },
      "outputs": [],
      "source": [
        "print(f\"Минимальный loss на тренировочной выборке: {min(losses['train']):.4f}\")\n",
        "print(f\"Минимальный loss на валидационной выборке: {min(losses['valid']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tld0SsdZLDsj",
      "metadata": {
        "id": "tld0SsdZLDsj"
      },
      "source": [
        "#### Анализ качества модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a733363f-5520-4d35-9511-8afce7454b1c",
      "metadata": {
        "id": "a733363f-5520-4d35-9511-8afce7454b1c"
      },
      "outputs": [],
      "source": [
        "FC_model.to('cpu')\n",
        "\n",
        "start = 0\n",
        "\n",
        "predicted_steps = 220\n",
        "# predicted_steps = 100\n",
        "# predicted_steps = 50\n",
        "# predicted_steps = 5\n",
        "\n",
        "in_data = solar_test_scaled.values[start:start+N_LAGS].reshape(-1)\n",
        "for i in range(predicted_steps):\n",
        "    out_data = FC_model(torch.tensor(in_data[-N_LAGS:], dtype=torch.float32), HORIZON)\n",
        "    in_data = np.concatenate((in_data, out_data.detach().numpy()))\n",
        "\n",
        "fc_pred = in_data[start+N_LAGS:]\n",
        "plt.plot(\n",
        "    solar_test_scaled.values[start+N_LAGS:start+predicted_steps*HORIZON],\n",
        "    label=\"Целевые значения\")\n",
        "plt.plot(fc_pred, label=\"Предсказания\");\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ItFGWpRNSAW",
      "metadata": {
        "id": "4ItFGWpRNSAW"
      },
      "source": [
        "Базовая модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-SexO4byMjRu",
      "metadata": {
        "id": "-SexO4byMjRu"
      },
      "outputs": [],
      "source": [
        "solar_baseline_pred = np.array(\n",
        "    [solar_test_scaled.mean() for _ in range(len(solar_test_scaled))])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1OKmDn4LOab",
      "metadata": {
        "id": "f1OKmDn4LOab"
      },
      "source": [
        "**MAE (Mean Absolute Error)**\n",
        "\n",
        "Средняя абсолютная ошибка:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9K1sIE7bPm3_",
      "metadata": {
        "id": "9K1sIE7bPm3_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "len_of_seq = np.min(\n",
        "    [fc_pred.shape[0], solar_test_scaled.values[N_LAGS:].shape[0]])\n",
        "\n",
        "fc_mae = mean_absolute_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    fc_pred[:len_of_seq]\n",
        ")\n",
        "\n",
        "baseline_mae = mean_absolute_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    solar_baseline_pred[:len_of_seq]\n",
        ")\n",
        "\n",
        "print(f\"FCNN MAE: {fc_mae:.4f}\")\n",
        "print(f\"Baseline MAE: {baseline_mae:.4f}\")\n",
        "\n",
        "MAE_prediction[f\"FCNN_{len_of_seq}\"] = fc_mae\n",
        "MAE_prediction[f\"Baseline_{len_of_seq}\"] = baseline_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GdVVCsRdR9e8",
      "metadata": {
        "id": "GdVVCsRdR9e8"
      },
      "source": [
        "**RMSE (Root Mean Squared Error)**\n",
        "\n",
        "Корень из средней квадратичной ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vlZAFnbeQ58j",
      "metadata": {
        "id": "vlZAFnbeQ58j"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "fc_rmse = mean_squared_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    fc_pred[:len_of_seq]\n",
        ")\n",
        "\n",
        "baseline_rmse = mean_squared_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    solar_baseline_pred[:len_of_seq]\n",
        ")\n",
        "\n",
        "print(f\"FCNN RMSE: {fc_rmse:.4f}\")\n",
        "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
        "\n",
        "RMSE_prediction[f\"FCNN_{len_of_seq}\"] = fc_rmse\n",
        "RMSE_prediction[f\"Baseline_{len_of_seq}\"] = baseline_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pXEC2PHA7Z_k",
      "metadata": {
        "id": "pXEC2PHA7Z_k"
      },
      "source": [
        "### Рекуррентная нейронная сеть (RNN)\n",
        "\n",
        "<!-- <img src=\"https://habrastorage.org/getpro/habr/post_images/a71/91e/86a/a7191e86a40565f276bed7327c2c8ead.png\" alt=\"trend_seasonality\" width=\"800\"  align=\"center\"/> -->\n",
        "<img src=\"https://github.com/ArtyomShabunin/SMOPA-25/blob/main/imgs/RNN.jpg?raw=true\" alt=\"trend_seasonality\" width=\"500\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "**Преимущества RNN:**\n",
        "\n",
        "1. **Учет временных зависимостей**  \n",
        "   RNN умеют **запоминать информацию о предыдущих состояниях**, что позволяет учитывать порядок значений — ключевая особенность временных рядов.\n",
        "\n",
        "2. **Гибкость по длине входа/выхода**  \n",
        "   Можно подавать последовательности **разной длины**, и сеть может генерировать выходные последовательности также разной длины — удобно для задач с переменной длиной данных.\n",
        "\n",
        "3. **Плавное моделирование трендов и сезонности**  \n",
        "   Благодаря \"памяти\" может захватывать как **локальные**, так и **долгосрочные зависимости** (особенно в сочетании с LSTM/GRU).\n",
        "\n",
        "4. **Хорошо подходят для многомерных временных рядов**  \n",
        "   Можно одновременно подавать несколько сигналов/каналов (например, температуру, давление и т.п.) и прогнозировать на их основе.\n",
        "\n",
        "---\n",
        "\n",
        "**Недостатки RNN:**\n",
        "\n",
        "1. **Проблемы с долгосрочной памятью**  \n",
        "   Обычные RNN страдают от **затухающего или взрывающегося градиента**, что мешает эффективно захватывать зависимости на больших интервалах времени. (Для этого придумали LSTM и GRU.)\n",
        "\n",
        "2. **Медленная и последовательная обработка**  \n",
        "   Обработка последовательностей **непараллельна** — каждое состояние зависит от предыдущего. Это усложняет обучение и замедляет предсказания.\n",
        "\n",
        "3. **Сложнее обучать и отлаживать**  \n",
        "   RNN чувствительны к выбору гиперпараметров, начальным весам и другим деталям. Могут \"залипать\" в локальных минимумах.\n",
        "\n",
        "4. **Большая потребность в данных**  \n",
        "   Для качественного обучения RNN **нужно больше данных**, особенно если прогнозируется длинный горизонт.\n",
        "\n",
        "5. **Проблемы со стационарностью и масштабированием**  \n",
        "   При нестабильных данных без нормализации RNN может \"плыть\". Также она может хуже работать, если данные сильно изменяются со временем (например, резкие скачки и выбросы)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tudDawpgr6Bv",
      "metadata": {
        "id": "tudDawpgr6Bv"
      },
      "source": [
        "**LSTM (Long Short-Term Memory)** — это **тип рекуррентной нейронной сети (RNN)**, разработанный для лучшего захвата **долгосрочных зависимостей** во временных рядах.  \n",
        "В отличие от обычной RNN, LSTM **умело управляет памятью** — решает проблему **затухающего градиента**, благодаря чему может \"помнить\" важные события, случившиеся десятки или сотни шагов назад.\n",
        "\n",
        "Внутри LSTM есть три \"входа\":\n",
        "- **Forget gate** — решает, что выбросить из памяти.\n",
        "- **Input gate** — решает, что сохранить.\n",
        "- **Output gate** — решает, что отдать наружу в текущем шаге.\n",
        "\n",
        "Это делает LSTM особенно хорошим для сложных последовательностей: язык, время, сигналы и т.д.\n",
        "\n",
        "---\n",
        "\n",
        "**Autoregressive LSTM** — это **способ применения LSTM**, при котором модель **пошагово предсказывает будущее, используя собственные предыдущие предсказания как вход**.\n",
        "\n",
        "<img src=\"https://github.com/ArtyomShabunin/SMOPA-25/blob/main/imgs/Autoregressive_LSTM.png?raw=true\" alt=\"trend_seasonality\" width=\"500\"  align=\"center\"/>\n",
        "\n",
        "Как это работает:\n",
        "1. Модель получает входные данные (например, 23 прошлых значений).\n",
        "2. Предсказывает следующий шаг (например, $ y_{t+1} $).\n",
        "3. Этот предсказанный $ y_{t+1} $ подаётся обратно на вход, чтобы предсказать $ y_{t+2} $.\n",
        "4. И так далее — autoregressive = \"автоподкорм\".\n",
        "\n",
        "---\n",
        "\n",
        "Преимущества autoregressive LSTM:\n",
        "- Позволяет строить **прогноз на произвольное количество шагов вперёд**, даже если модель обучалась предсказывать только 1 шаг.\n",
        "- Модель может **накапливать эффект ошибок или трендов** — иногда это даже полезно.\n",
        "\n",
        "Недостатки:\n",
        "- Ошибки **накапливаются** с каждым шагом: если модель ошиблась на $ t+1 $, следующая ошибка будет ещё больше.\n",
        "- Модель **не учится предсказывать сразу всю последовательность** — только по одному шагу, что может быть неэффективно для некоторых задач.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YLFjy8gk7ZQP",
      "metadata": {
        "id": "YLFjy8gk7ZQP"
      },
      "outputs": [],
      "source": [
        "class LSTMForecastAuto(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_seq, horizon):\n",
        "        outputs = []\n",
        "\n",
        "        input_seq = input_seq.unsqueeze(2)\n",
        "\n",
        "        lstm_out, (hn, cn) = self.lstm(input_seq)\n",
        "        # lstm_out - gоследовательность выходов LSTM на каждом шаге во времени (input_seq, batch_size, hidden_size)\n",
        "        # hn - последнее скрытое состояние  (hidden state) для каждого слоя (num_layers, batch_size, hidden_size)\n",
        "        # cn - состояние памяти (cell state) вторая часть \"долгосрочной памяти\" LSTM,\n",
        "        # которая помогает сети \"запоминать\" долгосрочные зависимости (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        pred = self.linear(lstm_out[:, -1, :])  # [batch, 1]\n",
        "        outputs.append(pred)\n",
        "        input = pred.unsqueeze(1)\n",
        "\n",
        "        for _ in range(horizon - 1):\n",
        "            out, (hn, cn) = self.lstm(input, (hn, cn))\n",
        "            pred = self.linear(out[:, -1, :])\n",
        "            outputs.append(pred)\n",
        "            input = pred.unsqueeze(1)\n",
        "\n",
        "        return torch.cat(outputs, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bh3qJaKjrMbn",
      "metadata": {
        "id": "bh3qJaKjrMbn"
      },
      "source": [
        "Создадим новые ```solar_train_loader``` и ```solar_train_loader```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zCJ05CnrmOBm",
      "metadata": {
        "id": "zCJ05CnrmOBm"
      },
      "outputs": [],
      "source": [
        "N_LAGS = 20\n",
        "HORIZON = 20\n",
        "\n",
        "solar_dataset = SolarDataset(solar_train_scaled.values, N_LAGS, HORIZON)\n",
        "\n",
        "solar_train_size = int(0.8 * len(solar_dataset))\n",
        "solar_valid_size = len(solar_dataset) - solar_train_size\n",
        "\n",
        "solar_train_dataset = Subset(solar_dataset, range(solar_train_size))\n",
        "solar_valid_dataset = Subset(\n",
        "    solar_dataset, range(solar_train_size, solar_train_size + solar_valid_size))\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "solar_train_loader = DataLoader(solar_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "solar_valid_loader = DataLoader(solar_valid_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2JI51ctytQ9g",
      "metadata": {
        "id": "2JI51ctytQ9g"
      },
      "source": [
        "Инициализация и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iR18IzNCJwRY",
      "metadata": {
        "id": "iR18IzNCJwRY"
      },
      "outputs": [],
      "source": [
        "HIDDEN_SIZE = 16\n",
        "LSTM_LAYERS = 1\n",
        "\n",
        "LSTM_model = LSTMForecastAuto(hidden_size=HIDDEN_SIZE, num_layers=LSTM_LAYERS).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=0.01)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3,\n",
        "                                           patience=3, threshold=0.0001)\n",
        "\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8n_4tmTH7ZWv",
      "metadata": {
        "id": "8n_4tmTH7ZWv"
      },
      "outputs": [],
      "source": [
        "LSTM_model, losses, lr = train_model(LSTM_model, loss_fn, optimizer, scheduler, num_epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cj_CAjc2Fi0E",
      "metadata": {
        "id": "cj_CAjc2Fi0E"
      },
      "outputs": [],
      "source": [
        "plt.plot(lr);\n",
        "plt.xlabel(\"Эпоха\");\n",
        "plt.ylabel(\"Коэффициент скорости обучения\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fWqaA43AcMSr",
      "metadata": {
        "id": "fWqaA43AcMSr"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses[\"train\"], label=\"Обучающая выборка\");\n",
        "plt.plot(losses[\"valid\"], label=\"Валидационная выборка\");\n",
        "plt.legend();\n",
        "plt.xlabel(\"Эпоха\");\n",
        "plt.ylabel(\"Среднеквадратичная ошибка\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1aef63-dc1f-4b43-9f10-ba83a4912c1d",
      "metadata": {
        "id": "cc1aef63-dc1f-4b43-9f10-ba83a4912c1d"
      },
      "outputs": [],
      "source": [
        "print(f\"Минимальный loss на тренировочной выборке: {min(losses['train']):.4f}\")\n",
        "print(f\"Минимальный loss на валидационной выборке: {min(losses['valid']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UZpz6WcjuR1a",
      "metadata": {
        "id": "UZpz6WcjuR1a"
      },
      "source": [
        "#### Анализ качества модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48Fpo_OKZk2_",
      "metadata": {
        "id": "48Fpo_OKZk2_"
      },
      "outputs": [],
      "source": [
        "LSTM_model.to('cpu')\n",
        "\n",
        "\n",
        "horizon_for_test = solar_test_scaled.shape[0] - N_LAGS\n",
        "# horizon_for_test = 2000\n",
        "# horizon_for_test = 1000\n",
        "# horizon_for_test = 200\n",
        "\n",
        "lstm_pred = LSTM_model(\n",
        "    torch.tensor(\n",
        "        solar_test_scaled.values[:N_LAGS].reshape(-1)[None,:],\n",
        "        dtype=torch.float32),\n",
        "    horizon_for_test\n",
        "    )[0]\n",
        "\n",
        "plt.plot(solar_test_scaled.values[N_LAGS:N_LAGS+horizon_for_test].reshape(-1), label=\"Целевые значения\");\n",
        "plt.plot(lstm_pred.detach().numpy(), label=\"Предсказания\");\n",
        "\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77cVXNO8vAPo",
      "metadata": {
        "id": "77cVXNO8vAPo"
      },
      "source": [
        "**MAE (Mean Absolute Error)**\n",
        "\n",
        "Средняя абсолютная ошибка:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5kTng_B4Zk-I",
      "metadata": {
        "id": "5kTng_B4Zk-I"
      },
      "outputs": [],
      "source": [
        "len_of_seq = np.min(\n",
        "    [lstm_pred.shape[0], solar_test_scaled.values[N_LAGS:,:].shape[0]])\n",
        "\n",
        "lstm_mae = mean_absolute_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    lstm_pred[:len_of_seq].detach().numpy()\n",
        ")\n",
        "\n",
        "baseline_mae = mean_absolute_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    solar_baseline_pred[N_LAGS:][:len_of_seq]\n",
        ")\n",
        "\n",
        "print(f\"LSTM MAE: {lstm_mae:.4f}\")\n",
        "print(f\"Baseline MAE: {baseline_mae:.4f}\")\n",
        "\n",
        "MAE_prediction[f\"LSTM_{len_of_seq}\"] = lstm_mae\n",
        "MAE_prediction[f\"Baseline_{len_of_seq}\"] = baseline_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cqNrkf2nx0ye",
      "metadata": {
        "id": "cqNrkf2nx0ye"
      },
      "source": [
        "**RMSE (Root Mean Squared Error)**\n",
        "\n",
        "Корень из средней квадратичной ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XLr92SWxn15l",
      "metadata": {
        "id": "XLr92SWxn15l"
      },
      "outputs": [],
      "source": [
        "lstm_rmse = mean_squared_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    lstm_pred[:len_of_seq].detach().numpy()\n",
        ")\n",
        "\n",
        "baseline_rmse = mean_squared_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq],\n",
        "    solar_baseline_pred[:len_of_seq]\n",
        ")\n",
        "\n",
        "print(f\"LSTM RMSE: {lstm_rmse:.4f}\")\n",
        "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
        "\n",
        "RMSE_prediction[f\"LSTM_{len_of_seq}\"] = lstm_rmse\n",
        "RMSE_prediction[f\"Baseline_{len_of_seq}\"] = baseline_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4J4PHH4-y4Ev",
      "metadata": {
        "id": "4J4PHH4-y4Ev"
      },
      "source": [
        "### LSTM с дополнительными признаками для учета сезонности"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qwFN-NJmzZyX",
      "metadata": {
        "id": "qwFN-NJmzZyX"
      },
      "source": [
        "Синусоидальные преобразования временных признаков — это **популярный способ добавить в модель информацию о сезонности или периодичности**, особенно в задачах временных рядов. Давай коротко, но по делу: что это, зачем, как использовать, и примеры.\n",
        "\n",
        "---\n",
        "\n",
        "Временными метки (например, час, день недели, месяц) - **циклические**. Например:\n",
        "- 23:00 → 0:00 → 1:00 — это не просто увеличение, а переход по кругу;\n",
        "- Понедельник → воскресенье → понедельник.\n",
        "\n",
        "Чтобы модель понимала, что **0 и 23 часа \"близки\"**, применяют синусоиду и косинус:\n",
        "\n",
        "```python\n",
        "sin_val = sin(2π * t / T)\n",
        "cos_val = cos(2π * t / T)\n",
        "```\n",
        "\n",
        "где:\n",
        "- `t` — значение (например, час от 0 до 23);\n",
        "- `T` — длина цикла (например, 24 для часов в сутках).\n",
        "\n",
        "---\n",
        "\n",
        "Без синуса/косинуса:\n",
        "- `0` и `23` далеки (23 - 0 = 23), хотя на самом деле они \"рядом\" по времени.\n",
        "- Модель не видит периодичности, теряется фаза цикла.\n",
        "\n",
        "С синусом/косинусом:\n",
        "- значения образуют **единичную окружность** → правильно отображают цикличность;\n",
        "- модель получает контекст: \"где во времени находится точка\".\n",
        "\n",
        "---\n",
        "\n",
        "Синусоидальные преобразования — **простой и мощный способ** научить модель чувствовать **время и циклы**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QK2M-Rfb0MjK",
      "metadata": {
        "id": "QK2M-Rfb0MjK"
      },
      "source": [
        "Добавим новые признаки в наши данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7QeM2sLr0FmO",
      "metadata": {
        "id": "7QeM2sLr0FmO"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('intermittent-renewables-production-france.csv')\n",
        "df = df.rename(columns={'Date and Hour' : 'DateTime'})\n",
        "df['DateTime'] = df['DateTime'].str.slice(stop=-6)\n",
        "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "\n",
        "df['sin_dayOfYear'] = np.sin(2*np.pi*df['dayOfYear']/365)\n",
        "df['cos_dayOfYear'] = np.cos(2*np.pi*df['dayOfYear']/365)\n",
        "\n",
        "df = df.sort_values(ascending=True,by='DateTime')\n",
        "df = df.drop(['Date','dayName','monthName', 'dayOfYear'],axis=1)\n",
        "df = df.dropna()\n",
        "df = df.set_index(\"DateTime\")\n",
        "\n",
        "df['sin_dayOfHour'] = np.sin(2*np.pi*df.index.hour/24)\n",
        "df['cos_dayOfHour'] = np.cos(2*np.pi*df.index.hour/24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wd0I-R2l0Fpe",
      "metadata": {
        "id": "Wd0I-R2l0Fpe"
      },
      "outputs": [],
      "source": [
        "solar = df[df['Source'] == 'Solar'][[\n",
        "    'Production',\n",
        "    'sin_dayOfYear', 'cos_dayOfYear',\n",
        "    'sin_dayOfHour', 'cos_dayOfHour']]\n",
        "solar.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eGwsDjC42-i4",
      "metadata": {
        "id": "eGwsDjC42-i4"
      },
      "outputs": [],
      "source": [
        "solar['sin_dayOfYear'].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f023f7d1-31a2-4727-b58f-345bd041ac14",
      "metadata": {
        "id": "f023f7d1-31a2-4727-b58f-345bd041ac14"
      },
      "outputs": [],
      "source": [
        "solar['sin_dayOfHour'].plot();\n",
        "plt.xlim(['2021-01-01','2021-01-03']);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OXZVTzoD0Rvm",
      "metadata": {
        "id": "OXZVTzoD0Rvm"
      },
      "source": [
        "Делим данные на тренировочную и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pOGOEUnd3Pwv",
      "metadata": {
        "id": "pOGOEUnd3Pwv"
      },
      "outputs": [],
      "source": [
        "cutoff_date = '2023-01-01'\n",
        "\n",
        "solar_train = solar[solar.index < cutoff_date].copy()\n",
        "solar_test = solar[solar.index >= cutoff_date].copy()\n",
        "\n",
        "print(f\"Test: {solar_test.shape[0]} записей\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5PRGfnK0ZT6",
      "metadata": {
        "id": "c5PRGfnK0ZT6"
      },
      "source": [
        "Масштабируем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EsIEydny3UU0",
      "metadata": {
        "id": "EsIEydny3UU0"
      },
      "outputs": [],
      "source": [
        "solar_scaler = preprocessing.MinMaxScaler() # нормализация данных\n",
        "# solar_scaler = preprocessing.StandardScaler() # стандартизация данных\n",
        "\n",
        "solar_train_scaled = pd.DataFrame(\n",
        "    solar_scaler.fit_transform(solar_train.values[:]),\n",
        "    index=solar_train.index)\n",
        "\n",
        "solar_test_scaled = pd.DataFrame(\n",
        "    solar_scaler.transform(solar_test.values[:]),\n",
        "    index=solar_test.index)\n",
        "\n",
        "solar_train_scaled.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5qtbf_SD3UYT",
      "metadata": {
        "id": "5qtbf_SD3UYT"
      },
      "outputs": [],
      "source": [
        "solar_train_scaled[2].plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_sxyIqrt0kPw",
      "metadata": {
        "id": "_sxyIqrt0kPw"
      },
      "source": [
        "Создаем новый Dataset и Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jnw7lsOZ0Fsq",
      "metadata": {
        "id": "Jnw7lsOZ0Fsq"
      },
      "outputs": [],
      "source": [
        "class SolarDatasetWithSin(Dataset):\n",
        "    def __init__(self, data, n_lags, horizon):\n",
        "        self.n_lags = n_lags\n",
        "        self.horizon = horizon\n",
        "        data = data\n",
        "        self.x = torch.tensor(data[:-self.horizon], dtype=torch.float32)\n",
        "        self.y = torch.tensor(data[self.n_lags:],dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx:idx+self.n_lags], self.y[idx:idx+self.horizon]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y.shape[0]-self.horizon+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sgK8i8_Q0Fwp",
      "metadata": {
        "id": "sgK8i8_Q0Fwp"
      },
      "outputs": [],
      "source": [
        "N_LAGS = 20\n",
        "HORIZON = 20\n",
        "\n",
        "solar_dataset = SolarDatasetWithSin(solar_train_scaled.values, N_LAGS, HORIZON)\n",
        "\n",
        "solar_train_size = int(0.8 * len(solar_dataset))\n",
        "solar_valid_size = len(solar_dataset) - solar_train_size\n",
        "\n",
        "solar_train_dataset = Subset(solar_dataset, range(solar_train_size))\n",
        "solar_valid_dataset = Subset(\n",
        "    solar_dataset, range(solar_train_size, solar_train_size + solar_valid_size))\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "solar_train_loader = DataLoader(solar_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "solar_valid_loader = DataLoader(solar_valid_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wSePiZjd1Jxt",
      "metadata": {
        "id": "wSePiZjd1Jxt"
      },
      "source": [
        "Определяем новую модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-7olXYVm3c-7",
      "metadata": {
        "id": "-7olXYVm3c-7"
      },
      "outputs": [],
      "source": [
        "class LSTMForecastAuto2(nn.Module):\n",
        "    def __init__(self, input_size=3, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, input_seq, horizon):\n",
        "        outputs = []\n",
        "\n",
        "        # Прогоняем весь input_seq и получаем hidden state\n",
        "        lstm_out, (hn, cn) = self.lstm(input_seq)\n",
        "\n",
        "        # Берем последний выход и делаем первое предсказание\n",
        "        pred = self.linear(lstm_out[:, -1, :])         # [batch, input_size]\n",
        "        outputs.append(pred.unsqueeze(1))              # [batch, 1, input_size]\n",
        "        input_step = pred.unsqueeze(1)                 # для следующего шага\n",
        "\n",
        "        for _ in range(horizon - 1):\n",
        "            out, (hn, cn) = self.lstm(input_step, (hn, cn))\n",
        "            pred = self.linear(out[:, -1, :])          # [batch, input_size]\n",
        "            outputs.append(pred.unsqueeze(1))          # [batch, 1, input_size]\n",
        "            input_step = pred.unsqueeze(1)\n",
        "\n",
        "        return torch.cat(outputs, dim=1)               # [batch, horizon, input_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WQAi--Ry1P5C",
      "metadata": {
        "id": "WQAi--Ry1P5C"
      },
      "source": [
        "Инициализируем и обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wMMkG4Ny5w0-",
      "metadata": {
        "id": "wMMkG4Ny5w0-"
      },
      "outputs": [],
      "source": [
        "HIDDEN_SIZE = 16\n",
        "LSTM_LAYERS = 1\n",
        "\n",
        "LSTM_model_2 = LSTMForecastAuto2(input_size=5, hidden_size=HIDDEN_SIZE, num_layers=LSTM_LAYERS).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(LSTM_model_2.parameters(), lr=0.01)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3,\n",
        "                                           patience=3, threshold=0.0001)\n",
        "\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_0xZ3dHl8dHu",
      "metadata": {
        "id": "_0xZ3dHl8dHu"
      },
      "outputs": [],
      "source": [
        "LSTM_model_2, losses, lr = train_model(LSTM_model_2, loss_fn, optimizer, scheduler, num_epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unWGBJNo9vp-",
      "metadata": {
        "id": "unWGBJNo9vp-"
      },
      "outputs": [],
      "source": [
        "plt.plot(lr);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RE3q6zjqCE1P",
      "metadata": {
        "id": "RE3q6zjqCE1P"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses[\"train\"], label=\"Обучающая выборка\");\n",
        "plt.plot(losses[\"valid\"], label=\"Валидационная выборка\");\n",
        "plt.legend();\n",
        "plt.xlabel(\"Эпоха\");\n",
        "plt.ylabel(\"Среднеквадратичная ошибка\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nC1gpFu4CE3j",
      "metadata": {
        "id": "nC1gpFu4CE3j"
      },
      "outputs": [],
      "source": [
        "print(f\"Минимальный loss на тренировочной выборке: {min(losses['train']):.4f}\")\n",
        "print(f\"Минимальный loss на валидационной выборке: {min(losses['valid']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcxWnyuE2r2w",
      "metadata": {
        "id": "bcxWnyuE2r2w"
      },
      "source": [
        "#### Анализ качества модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jopGzHLwCE6k",
      "metadata": {
        "id": "jopGzHLwCE6k"
      },
      "outputs": [],
      "source": [
        "LSTM_model_2.to('cpu')\n",
        "\n",
        "horizon_for_test = solar_test_scaled.shape[0] - N_LAGS\n",
        "# horizon_for_test = 2000\n",
        "# horizon_for_test = 1000\n",
        "# horizon_for_test = 200\n",
        "\n",
        "lstm2_pred = LSTM_model_2(\n",
        "    torch.tensor(\n",
        "        solar_test_scaled.values[:N_LAGS][None,:,:],\n",
        "        dtype=torch.float32),\n",
        "    horizon_for_test\n",
        "    )[0]\n",
        "\n",
        "plt.plot(solar_test_scaled.values[N_LAGS:N_LAGS+horizon_for_test][:,0],\n",
        "         label=\"Целевые значения\");\n",
        "plt.plot(lstm2_pred[:,0].detach().numpy(), label=\"Предсказания\");\n",
        "\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UGbvZWKX3tEv",
      "metadata": {
        "id": "UGbvZWKX3tEv"
      },
      "source": [
        "**MAE (Mean Absolute Error)**\n",
        "\n",
        "Средняя абсолютная ошибка:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ED5zEdCejZ",
      "metadata": {
        "id": "29ED5zEdCejZ"
      },
      "outputs": [],
      "source": [
        "len_of_seq = np.min(\n",
        "    [lstm2_pred.shape[0], solar_test_scaled.values[N_LAGS:,:].shape[0]])\n",
        "\n",
        "lstm2_mae = mean_absolute_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq][:,0],\n",
        "    lstm2_pred[:len_of_seq].detach().numpy()[:,0]\n",
        ")\n",
        "\n",
        "baseline_mae = mean_absolute_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq][:,0],\n",
        "    solar_baseline_pred[N_LAGS:][:len_of_seq]\n",
        ")\n",
        "\n",
        "print(f\"LSTM2 MAE: {lstm2_mae:.4f}\")\n",
        "print(f\"Baseline MAE: {baseline_mae:.4f}\")\n",
        "\n",
        "MAE_prediction[f\"LSTM2_{len_of_seq}\"] = lstm2_mae\n",
        "MAE_prediction[f\"Baseline_{len_of_seq}\"] = baseline_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a_NdxllU6f83",
      "metadata": {
        "id": "a_NdxllU6f83"
      },
      "source": [
        "**RMSE (Root Mean Squared Error)**\n",
        "\n",
        "Корень из средней квадратичной ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2MSqc3MZ4wmc",
      "metadata": {
        "id": "2MSqc3MZ4wmc"
      },
      "outputs": [],
      "source": [
        "lstm2_rmse = mean_squared_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq][:,0],\n",
        "    lstm2_pred[:len_of_seq].detach().numpy()[:,0]\n",
        ")\n",
        "\n",
        "baseline_rmse = mean_squared_error(\n",
        "    solar_test_scaled.values[N_LAGS:][:len_of_seq][:,0],\n",
        "    solar_baseline_pred[N_LAGS:][:len_of_seq]\n",
        ")\n",
        "\n",
        "print(f\"LSTM2 RMSE: {lstm2_rmse:.4f}\")\n",
        "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
        "\n",
        "RMSE_prediction[f\"LSTM2_{len_of_seq}\"] = lstm2_rmse\n",
        "RMSE_prediction[f\"Baseline_{len_of_seq}\"] = baseline_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O8-7rLzlfHt1",
      "metadata": {
        "id": "O8-7rLzlfHt1"
      },
      "source": [
        "### Сравнение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "li7m5FrP3k-i",
      "metadata": {
        "id": "li7m5FrP3k-i"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(\n",
        "    [MAE_prediction, RMSE_prediction],\n",
        "    index=['MAE', 'RMSE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xEM3-vfreHqu",
      "metadata": {
        "id": "xEM3-vfreHqu"
      },
      "outputs": [],
      "source": [
        "df.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RA2tciWTg6g4",
      "metadata": {
        "id": "RA2tciWTg6g4"
      },
      "outputs": [],
      "source": [
        "# df.transpose()[[\"1000\" in i for i in df.transpose().index]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZYzG302IHeIq",
      "metadata": {
        "id": "ZYzG302IHeIq"
      },
      "outputs": [],
      "source": [
        "print(f\"Число параметров FC модели: {sum(p.numel() for p in FC_model.parameters() if p.requires_grad)}\")\n",
        "print(f\"Число параметров LSTM модели: {sum(p.numel() for p in LSTM_model.parameters() if p.requires_grad)}\")\n",
        "print(f\"Число параметров LSTM модели с доп. признаками: {sum(p.numel() for p in LSTM_model_2.parameters() if p.requires_grad)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5k-ahVfqH7Vq",
      "metadata": {
        "id": "5k-ahVfqH7Vq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}