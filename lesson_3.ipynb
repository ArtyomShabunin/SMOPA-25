{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtyomShabunin/SMOPA-25/blob/main/lesson_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cin47mk26Y6L",
      "metadata": {
        "id": "cin47mk26Y6L"
      },
      "source": [
        "<img src=\"https://prana-system.com/files/110/rds_color_full.png\" alt=\"tot image\" width=\"300\"  align=\"center\"/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src=\"https://mpei.ru/AboutUniverse/OficialInfo/Attributes/PublishingImages/logo1.jpg\" alt=\"mpei image\" width=\"200\" align=\"center\"/>\n",
        "<img src=\"https://mpei.ru/Structure/Universe/tanpe/structure/tfhe/PublishingImages/tot.png\" alt=\"tot image\" width=\"100\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "# **Системы машинного обучения и предиктивной аналитики в тепловой и возобновляемой энергетике**  \n",
        "\n",
        "# ***Практические занятия***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ad48e5-1a3e-47bb-b3ca-46dc7e3e16c0",
      "metadata": {
        "id": "61ad48e5-1a3e-47bb-b3ca-46dc7e3e16c0"
      },
      "source": [
        "# Занятие №3\n",
        "# Поиск аномалий методами машинного обучения\n",
        "\n",
        "**5 марта 2025г.**\n",
        "\n",
        "---\n",
        "\n",
        "С точки зрения машинного оучения задачу поиска поиска аномалий можно разделить на два возможных типа:\n",
        "* **Outlier detection** (поиск выбросов): в тренировочной выборке содержатся выбросы, которые определяются как наблюдения, лежащие далеко от остальных. Таким образом, алгоритмы для детектирования выбросов пытаются найти регионы, где сосредоточена основная масса тренировочных данных, игрорируя аномальные наблюдения.\n",
        "* **Novelty detection** (поиск \"новизны\"): тренировочная выборка не загрязнена выбросами, и мы хотим научиться отвечать на вопрос \"является ли новое наблюдение выбросом\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fede1f-1946-4213-a7aa-b0d44b8741c3",
      "metadata": {
        "id": "a1fede1f-1946-4213-a7aa-b0d44b8741c3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\", rc={'figure.figsize':(15,6)})\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e180eb-1504-40b4-818a-7ffeaf073fdc",
      "metadata": {
        "id": "26e180eb-1504-40b4-818a-7ffeaf073fdc"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tYKGKwliEiii",
      "metadata": {
        "id": "tYKGKwliEiii"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"./data.gzip\")\n",
        "\n",
        "# signals = [\n",
        "#     'GTA1.DBinPU.Aldi', 'GTA1.DBinPU.Alvna', 'GTA1.DBinPU.Alzzo',\n",
        "#     'GTA1.DBinPU.Bo', 'GTA1.DBinPU.fi', 'GTA1.DBinPU.nst',\n",
        "#     'GTA1.DBinPU.ntk', 'GTA1.DBinPU.P', 'GTA1.DBinPU.Pk', 'GTA1.DBinPU.Pvh',\n",
        "#     'GTA1.DBinPU.Qtg', 'GTA1.DBinPU.Tk', 'GTA1.DBinPU.Tn', 'GTA1.DBinPU.Tt']\n",
        "\n",
        "# data = data.loc[:, signals]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nR-ekcJGLBI1",
      "metadata": {
        "id": "nR-ekcJGLBI1"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5046c1f6-3c0f-4208-b1ce-4dafefb5646b",
      "metadata": {
        "id": "5046c1f6-3c0f-4208-b1ce-4dafefb5646b"
      },
      "source": [
        "Чтение файла с описанием сигналов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8c1c68-6961-4eb0-ba1c-917ae5c87e03",
      "metadata": {
        "id": "cb8c1c68-6961-4eb0-ba1c-917ae5c87e03"
      },
      "outputs": [],
      "source": [
        "with open(f'./option_0/description.json', 'r', encoding = \"utf-8\") as f:\n",
        "    description = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55014340-f820-4b05-b691-036b21fa0854",
      "metadata": {
        "id": "55014340-f820-4b05-b691-036b21fa0854"
      },
      "source": [
        "Составим словарь для трактовки наименований сигналов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91880fd-b580-4f59-b7bf-4758826308f9",
      "metadata": {
        "id": "c91880fd-b580-4f59-b7bf-4758826308f9"
      },
      "outputs": [],
      "source": [
        "kks_to_description = {param['real_kks']: f\"{param['description']}, [{param['unit']}]\"\n",
        "for param in description if param['real_kks'] in data.columns}\n",
        "\n",
        "description_to_kks = { f\"{param['description']}, [{param['unit']}]\": param['real_kks']\n",
        "for param in description if param['real_kks'] in data.columns}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JVX80_YTEsEI",
      "metadata": {
        "id": "JVX80_YTEsEI"
      },
      "source": [
        "### Деление на тренировочную и тестовую выборки\n",
        "\n",
        "Разделение данных на **тренировочную** и **тестовую** выборки необходимо для оценки качества модели машинного обучения и предотвращения переобучения.  \n",
        "\n",
        "**Основные цели разделения:**\n",
        "1. **Обучение модели** – тренировочная выборка (training set) используется для подбора параметров модели, на основе этих данных модель «учится» находить закономерности.  \n",
        "2. **Оценка обобщающей способности** – тестовая выборка (test set) служит для проверки, насколько хорошо модель работает на новых, невидимых данных ( как модель справляется с реальными задачами, которых она не видела во время обучения).  \n",
        "\n",
        "**Почему нельзя тестировать модель на тех же данных, на которых она обучалась?**\n",
        "Если модель тестировать на тех же данных, на которых она училась, она может просто «запомнить» их вместо того, чтобы действительно выявлять зависимости. Это приведёт к **переобучению** (overfitting), когда модель хорошо работает на обучающих данных, но плохо справляется с новыми примерами.  \n",
        "\n",
        "Обычно данные делят следующим образом:\n",
        "- **Тренировочная выборка** – 70-80%  \n",
        "- **Тестовая выборка** – 20-30%  \n",
        "\n",
        "Дополнительно иногда используют **валидационную выборку** (validation set) для подбора гиперпараметров модели.\n",
        "\n",
        "Сформируем тренировочную и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YFYWQ8KADgEP",
      "metadata": {
        "id": "YFYWQ8KADgEP"
      },
      "outputs": [],
      "source": [
        "shuffled_data = data.sample(frac=1)\n",
        "\n",
        "data_train = shuffled_data.iloc[:round(shuffled_data.shape[0]*0.8), :]\n",
        "data_test = shuffled_data.iloc[round(shuffled_data.shape[0]*0.8):, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JFlb7Kfut2Xv",
      "metadata": {
        "id": "JFlb7Kfut2Xv"
      },
      "source": [
        "Добавим шум на половину тестовых данных и отметим их как аномальные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "578d68f9-154b-49c1-b695-95a267fe0a7c",
      "metadata": {
        "id": "578d68f9-154b-49c1-b695-95a267fe0a7c"
      },
      "outputs": [],
      "source": [
        "def generate_binary_matrix(rows, cols, prob_ones=0.3):\n",
        "    matrix = np.zeros((rows, cols), dtype=int)  # Создаем матрицу из нулей\n",
        "\n",
        "    for i in range(rows):\n",
        "        # Генерируем случайные 0 и 1 с заданной вероятностью (без гарантированной 1)\n",
        "        row = np.random.choice([0, 1], size=cols, p=[1 - prob_ones, prob_ones])\n",
        "\n",
        "        # Если в строке нет 1, вставляем её в случайное место\n",
        "        if not np.any(row):\n",
        "            row[np.random.randint(0, cols)] = 1\n",
        "\n",
        "        matrix[i] = row  # Записываем строку в матрицу\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba629a1-4dee-486f-adb2-a69800562054",
      "metadata": {
        "id": "fba629a1-4dee-486f-adb2-a69800562054"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EtRazB5ilSmG",
      "metadata": {
        "id": "EtRazB5ilSmG"
      },
      "outputs": [],
      "source": [
        "NUMBER_OF_ANOMALY_POINTS = round(data_test.shape[0]*0.5)\n",
        "\n",
        "data_test[\"anomaly\"] = 0\n",
        "data_test.loc[\n",
        "    data_test.iloc[:NUMBER_OF_ANOMALY_POINTS].index, [\"anomaly\"]] = 1\n",
        "\n",
        "mask = generate_binary_matrix(NUMBER_OF_ANOMALY_POINTS, data.shape[1], prob_ones=0.2)\n",
        "\n",
        "bias = mask * np.random.choice(\n",
        "    np.linspace(-0.05,0.05,num=10),\n",
        "    size=[NUMBER_OF_ANOMALY_POINTS, data.shape[1]],\n",
        "    p=np.full(10,0.1))\n",
        "\n",
        "data_test.loc[\n",
        "    data_test.iloc[:NUMBER_OF_ANOMALY_POINTS].index,\n",
        "    data_test.columns != \"anomaly\"] = data_test[data_test[\"anomaly\"] == 1].loc[:,data_test.columns != \"anomaly\"] * (1 + bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4caea890-edfb-45c2-86c4-4eb6fdca096f",
      "metadata": {
        "id": "4caea890-edfb-45c2-86c4-4eb6fdca096f"
      },
      "outputs": [],
      "source": [
        "data_test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IboksJTUJ2C4",
      "metadata": {
        "id": "IboksJTUJ2C4"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure();\n",
        "\n",
        "KKS_FOR_PLOT = \"GTA1.DBinPU.ntk\"\n",
        "\n",
        "data_test[data_test[\"anomaly\"] == 0][KKS_FOR_PLOT].plot(style='.', label=\"Нормальные данные\");\n",
        "data_test[data_test[\"anomaly\"] == 1][KKS_FOR_PLOT].plot(style='.', label=\"Зашумленные данные\");\n",
        "plt.title(kks_to_description [KKS_FOR_PLOT], fontsize=20);\n",
        "plt.legend(prop={'size': 16});\n",
        "\n",
        "# fig.savefig('fig9.png', dpi=fig.dpi, bbox_inches='tight');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f92132-0e9b-4895-bb62-fe09f9404141",
      "metadata": {
        "id": "d6f92132-0e9b-4895-bb62-fe09f9404141"
      },
      "source": [
        "### Нормализация и стандартизация данных\n",
        "\n",
        "**Нормализация** и **стандартизация** данных – это методы предобработки, используемые для приведения данных к единому масштабу, что улучшает работу моделей машинного обучения.  \n",
        "\n",
        "**Зачем это нужно?**\n",
        "1. **Разные масштабы признаков**\n",
        "   - **Электрическая мощность** может измеряться в **кВт** (тысячи).\n",
        "   - **Температура газов за ГТУ** – в **°C** (сотни).\n",
        "   - **Положение топливного клапана** – в процентах (0-100).\n",
        "   Без приведения к единому масштабу модель может считать признаки с большими значениями более важными, что искажает результаты.\n",
        "\n",
        "2. **Ускорение сходимости градиентных методов**\n",
        "   Если признаки имеют разные диапазоны, градиентный спуск будет сходиться медленно или нестабильно.\n",
        "\n",
        "3. **Устойчивость к численным проблемам**\n",
        "   Некоторые алгоритмы (например, метод k-ближайших соседей, линейная регрессия, нейросети) чувствительны к масштабу данных.\n",
        "\n",
        "---\n",
        "\n",
        "**Разница между нормализацией и стандартизацией**\n",
        "\n",
        "| Метод          | Как работает | Когда применять |\n",
        "|---------------|-------------|----------------|\n",
        "| **Нормализация (Min-Max Scaling)** | Приводит значения к диапазону [0,1] или [-1,1]:  $$ x' = (x - min) / (max - min) $$ | Когда важны **границы диапазона** (например, при работе с нейросетями). |\n",
        "| **Стандартизация (Z-Score Scaling)** | Приводит к среднему 0 и стандартному отклонению 1: $$ x' = (x - \\mu) / \\sigma $$ | Когда данные имеют **гауссово распределение** или важны относительные отклонения. |\n",
        "\n",
        "---\n",
        "\n",
        "Стандартизацию стоит применять при использовании алгоритмов, которые основываются на измерении расстояний, например, k ближайших соседей или метод опорных векторов (SVM).\n",
        "\n",
        "Для поиска аномалий будем использовать модель на основе метода опорных векторов, поэтому выполним стандартизацию данных на которых будем обучать модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cb58c2-6766-478a-b54f-4466daf2e9bd",
      "metadata": {
        "id": "10cb58c2-6766-478a-b54f-4466daf2e9bd"
      },
      "outputs": [],
      "source": [
        "# scaler = preprocessing.MinMaxScaler() # нормализация даннх\n",
        "scaler = preprocessing.StandardScaler() # стандартизация данных\n",
        "\n",
        "X_train = pd.DataFrame(\n",
        "    scaler.fit_transform(data_train),\n",
        "    columns=data_train.columns,\n",
        "    index=data_train.index)\n",
        "\n",
        "X_test = pd.DataFrame(\n",
        "    scaler.transform(data_test[data.columns]),\n",
        "    columns=data.columns,\n",
        "    index=data_test.index)\n",
        "\n",
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba5d657-9cde-4bc7-bfa1-922e74472a43",
      "metadata": {
        "id": "fba5d657-9cde-4bc7-bfa1-922e74472a43"
      },
      "outputs": [],
      "source": [
        "# X_train = X_train.iloc[:round(0.1*X_train.shape[0]),:]\n",
        "# X_test = X_test.iloc[:round(0.1*X_train.shape[0]),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a3a5c6-291c-48df-a233-dd09e4677576",
      "metadata": {
        "id": "59a3a5c6-291c-48df-a233-dd09e4677576"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97803306-4e7c-4623-9674-9dc744fb259f",
      "metadata": {
        "id": "97803306-4e7c-4623-9674-9dc744fb259f"
      },
      "source": [
        "## Метод опорных векторов (Support Vector Machines — SVM)\n",
        "\n",
        "Один из наиболее популярных методов обучения, который применяется для решения задач классификации и регрессии. Основная идея метода заключается в построении гиперплоскости, разделяющей объекты выборки оптимальным способом. Алгоритм работает в предположении, что чем больше расстояние (зазор) между разделяющей гиперплоскостью и объектами разделяемых классов, тем меньше будет средняя ошибка классификатора.\n",
        "\n",
        "![svm image](https://frankworkshophome.wordpress.com/wp-content/uploads/2019/12/7-1.png)\n",
        "\n",
        "Класс OneClassSVM реализует одноклассную SVM, которая используется для обнаружения выбросов. Если мы имеем дело с задачей novelty detection, где для тренировки нам доступны только \"хорошие\" наблюдения без аномалий, то мы можем воспользоваться этой моделью и научиться для каждого нового наблюдения говорить, является ли оно аномальным или нет.\n",
        "\n",
        "Общая идея OneClassSVM преобразовать признаковое пространство и провести разделяющую гиперплоскость так, чтобы наблюдения лежали как можно дальше от начала координат.\n",
        "В результате мы получаем границу, по одну сторону которой максимально плотно упакованы наблюдения из нашей чистой тренировочной выборки, а по другую будут находится аномальные значения, не похожие на то, что алгоритм видел во время обучения.\n",
        "\n",
        "**Плюсы и минусы**  \n",
        "\\+ Благодаря kernel trick, модель способна проводить нелинейные разделяющие границы  \n",
        "\\+ Особенно удобно использовать, когда в данных недостаточно \"плохих\" наблюдений, чтобы использовать стандартный подход обучения с учителем — бинарную классификацию  \n",
        "\\- Может очень сильно переобучиться и выдавать большое количество ложно отрицательных результатов, если разделяющий зазор слишком мал  \n",
        "\\- И, конечно, нужно быть абсолютно уверенным, что тренировочные данные не содержат никаких выбросов, иначе алгоритм будет считать их нормальными наблюдениями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "911fd44f-d0ac-469c-ad02-e7d1d543fd28",
      "metadata": {
        "id": "911fd44f-d0ac-469c-ad02-e7d1d543fd28"
      },
      "outputs": [],
      "source": [
        "kernel = widgets.Dropdown(\n",
        "    options=['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    value='rbf',\n",
        "    description='Kernel:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "nu = widgets.FloatSlider(\n",
        "    value=0.1,\n",
        "    min=0,\n",
        "    max=1,\n",
        "    step=0.01,\n",
        "    description='nu:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        ")\n",
        "\n",
        "widgets.VBox([\n",
        "    widgets.Label('Тип ядра, который будет использоваться в алгоритме'),\n",
        "    kernel,\n",
        "    widgets.Label('Верхняя граница доли ошибок обучения и нижняя граница доли опорных векторов'),\n",
        "    nu])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c576a4f-a805-48dc-aa5c-70b4fc332cb3",
      "metadata": {
        "id": "3c576a4f-a805-48dc-aa5c-70b4fc332cb3"
      },
      "source": [
        "---\n",
        "\n",
        "One-Class SVM ищет границу, которая отделяет \"нормальные\" объекты от выбросов (аномалий). Ядро влияет на форму этой границы.\n",
        "\n",
        "- **`kernel='rbf'`** (радиальная функция) — самый универсальный вариант, **подходит для большинства задач**.\n",
        "- **Другие ядра (`linear`, `poly`, `sigmoid`)** могут работать лучше в специфических случаях, но требуют подбора параметров.\n",
        "\n",
        "---\n",
        "\n",
        "`nu` – это **гиперпараметр, управляющий чувствительностью модели** к аномалиям. Он задает **верхнюю границу доли выбросов** (аномалий) и **нижнюю границу доли опорных векторов** (управляет балансом между нормальными данными и выбросами).\n",
        "\n",
        "- `nu` принимает значения от **0 до 1**.\n",
        "- Чем **меньше `nu`**, тем **меньше** точек модель считает аномалиями (детекции только редких экстремальных выбросов).\n",
        "- Чем **больше `nu`**, тем **больше** точек будут признаны выбросами (обнаружение даже слабые аномалии).\n",
        "- **Типичное значение:** `nu=0.01` (1% выбросов) или `nu=0.1` (10% выбросов).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a536dc7c-2212-430f-b303-b5f5886feeff",
      "metadata": {
        "id": "a536dc7c-2212-430f-b303-b5f5886feeff"
      },
      "outputs": [],
      "source": [
        "ocsvm = OneClassSVM(kernel=kernel.value, nu=nu.value)\n",
        "ocsvm.fit(X_train)\n",
        "\n",
        "print(f\"Число опорных векторов - {ocsvm.n_support_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dEnx1DZ6gB2g",
      "metadata": {
        "id": "dEnx1DZ6gB2g"
      },
      "source": [
        "Оценим тестовые данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pK4GljN68-Ag",
      "metadata": {
        "id": "pK4GljN68-Ag"
      },
      "outputs": [],
      "source": [
        "data_test.loc[:,'anomaly_svm'] = (ocsvm.predict(X_test) == -1).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db545a9-33d5-455f-81e6-5b1534d638d2",
      "metadata": {
        "id": "8db545a9-33d5-455f-81e6-5b1534d638d2"
      },
      "source": [
        "### Визуализация аномальных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nb-zS0UU-P-I",
      "metadata": {
        "id": "nb-zS0UU-P-I"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure();\n",
        "\n",
        "signal = 'GTA1.DBinPU.P'\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly'] == 1][signal].index,\n",
        "    data_test[data_test['anomaly'] == 1][signal].values,\n",
        "    s=70, facecolors='none', edgecolors='r', label= \"Аномальные данные\");\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly_svm'] == 1][signal].index,\n",
        "    data_test[data_test['anomaly_svm'] == 1][signal].values,\n",
        "    s=10, facecolors='r', edgecolors='r', label= \"Выявлена аномалия\");\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly'] == 0][signal].index,\n",
        "    data_test[data_test['anomaly'] == 0][signal].values,\n",
        "    s=70, facecolors='none', edgecolors='g', label= \"Нормальные данные\");\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly_svm'] == 0][signal].index,\n",
        "    data_test[data_test['anomaly_svm'] == 0][signal].values,\n",
        "    s=10, facecolors='g', edgecolors='g', label= \"Не выявлена аномалия\");\n",
        "\n",
        "plt.title(kks_to_description [signal], fontsize=20);\n",
        "plt.legend(prop={'size': 16});\n",
        "\n",
        "# fig.savefig('fig10.png', dpi=fig.dpi, bbox_inches='tight');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43e9a48-8c95-490d-a371-6f27b5b9fe96",
      "metadata": {
        "id": "a43e9a48-8c95-490d-a371-6f27b5b9fe96"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    scat_1 = data_test.groupby('anomaly_svm').get_group(1)\n",
        "    scat_0 = data_test.groupby('anomaly_svm').get_group(0)\n",
        "except KeyError:\n",
        "    print(\"Не удалось разделить данные\")\n",
        "\n",
        "params_dropdown = widgets.Dropdown(\n",
        "    options=data_test.columns,\n",
        "    description='Параметр:',\n",
        "    disabled=False,\n",
        "    value=None\n",
        ")\n",
        "\n",
        "out = widgets.Output()\n",
        "display(out)\n",
        "\n",
        "with out:\n",
        "    display(params_dropdown)\n",
        "\n",
        "@out.capture()\n",
        "def params_dropdown_eventhandler(change):\n",
        "\n",
        "    clear_output()\n",
        "    display(params_dropdown)\n",
        "    # selected_param = selected_params_kks[list(selected_params_description).index(change.new)]\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(1, 1, figsize=(15,5))\n",
        "    plt.title(f\"{change.new} - {kks_to_description [change.new]}\")\n",
        "    plt.plot(scat_1[change.new], 'r.', markersize=5, label='Аномалии')\n",
        "    plt.plot(scat_0[change.new], 'g.', markersize=5, label='Норма')\n",
        "    plt.legend()\n",
        "    display(fig)\n",
        "\n",
        "params_dropdown.observe(params_dropdown_eventhandler, names='value')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78b89a5-c3ac-4c16-8a57-fb95e6793487",
      "metadata": {
        "id": "e78b89a5-c3ac-4c16-8a57-fb95e6793487"
      },
      "source": [
        "### Оценка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02983b9-4d3f-405c-bc38-61761fb55f9a",
      "metadata": {
        "id": "c02983b9-4d3f-405c-bc38-61761fb55f9a"
      },
      "source": [
        "`confusion_matrix` — это **матрица ошибок (матрица конфузии)**, которая показывает, насколько точно модель классифицирует объекты разных классов. Она помогает оценить качество классификации.  \n",
        "\n",
        "**Разбор компонентов:**\n",
        "- **TP (True Positive)** – модель правильно предсказала `1` (истинные положительные).  \n",
        "- **TN (True Negative)** – модель правильно предсказала `0` (истинные отрицательные).  \n",
        "- **FP (False Positive)** – модель ошибочно предсказала `1`, но был `0` (ложноположительные).  \n",
        "- **FN (False Negative)** – модель ошибочно предсказала `0`, но был `1` (ложноотрицательные).  \n",
        "\n",
        "---\n",
        "\n",
        "**Если много FP (ложноположительных)** → модель часто ошибочно классифицирует объекты как положительные → **плохая специфичность**.  \n",
        "**Если много FN (ложноотрицательных)** → модель пропускает настоящие положительные случаи → **низкая чувствительность**.  \n",
        "**Баланс между FP и FN важен в разных задачах** (например, в медицине лучше избегать FN, а в спаме – FP).  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dAnNkZINCwl",
      "metadata": {
        "id": "6dAnNkZINCwl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "conf_mat = confusion_matrix(data_test['anomaly'], data_test['anomaly_svm'])\n",
        "ConfusionMatrixDisplay(conf_mat).plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PRGe8AziNfOv",
      "metadata": {
        "id": "PRGe8AziNfOv"
      },
      "outputs": [],
      "source": [
        "tn, fp, fn, tp = conf_mat.ravel()\n",
        "print(\"True Negative:\", tn)\n",
        "print(\"False Negative:\", fn)\n",
        "print(\"True Positive:\", tp)\n",
        "print(\"False Positive:\", fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb3c54b-0df8-482c-a025-3bff66218451",
      "metadata": {
        "id": "5bb3c54b-0df8-482c-a025-3bff66218451"
      },
      "source": [
        "При оценке моделей машинного обучения важно понимать **accuracy (точность), precision (прецизионность), recall (полнота)** и **F1-score**. Они основаны на **confusion matrix** и помогают анализировать качество классификации.  \n",
        "\n",
        "---\n",
        "\n",
        "**1. Accuracy (доля правильных ответов)**  \n",
        "**Accuracy** — это **общая точность модели**, доля **правильно предсказанных объектов** среди всех (пропорция верно предсказанных наблюдений):  \n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n",
        "\n",
        "Информативна если классы **сбалансированы** (примерно одинаковое количество примеров каждого класса).  \n",
        "**Проблема:** Если классы **несбалансированы** (например, 95% класса 0 и 5% класса 1), модель может просто всегда предсказывать 0 и получить **95% accuracy, но это плохая модель!**  \n",
        "\n",
        "---\n",
        "\n",
        "**2. Precision (прецизионность, точность для положительного класса)**  \n",
        "**Precision** показывает, насколько предсказания **\"положительный\" (1)** действительно правильные (с какой вероятностью положительные предсказания правильные):  \n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "Полезна если важно **избежать ложных тревог (FP)**.  \n",
        "Пример: В **медицине (рак, COVID)**, если мы говорим пациенту \"у вас болезнь\", но он здоров (**FP**), это может быть катастрофично.  \n",
        "\n",
        "---\n",
        "\n",
        "**3. Recall (полнота, чувствительность, чувствительность для положительного класса)**  \n",
        "**Recall** показывает, сколько **реальных положительных случаев модель правильно нашла**:  \n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "Полезна если важно **не пропустить настоящие случаи (FN)**.  \n",
        "Пример: В **распознавании мошенничества** важно обнаружить **все мошеннические операции** (даже если появятся FP).  \n",
        "\n",
        "---\n",
        "\n",
        "**4. F1-score (среднее Precision и Recall)**  \n",
        "**F1-score** — это **среднее гармоническое precision и recall**, дающее баланс между FP и FN:  \n",
        "\n",
        "$$\n",
        "\\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "Если **классы несбалансированы**, и нужно одновременно учитывать precision и recall.  \n",
        "Если важно **не только избежать ложных тревог, но и не пропустить важные случаи**.  \n",
        "\n",
        "---\n",
        "\n",
        "- **Accuracy** хороша при **равномерном распределении классов**.  \n",
        "- **Precision** и **recall** важны в **несбалансированных данных**.  \n",
        "- **F1-score** балансирует между precision и recall.  \n",
        "\n",
        "Чтобы получить полное понимание качества модели следует использовать **несколько метрик вместе**!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w-wiSwbOgKYx",
      "metadata": {
        "id": "w-wiSwbOgKYx"
      },
      "source": [
        "***accuracy*** - пропорция верно предсказанных наблюдений  \n",
        "***precision*** - с какой вероятностью положительные предсказания правильные  \n",
        "***recall*** - отражает способность модели определять наблюдения положительного класса  \n",
        "***F1*** - какое количество названных положительными наблюдений являются истинноположительными:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bqdjXN-4XR9j",
      "metadata": {
        "id": "bqdjXN-4XR9j"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f\"accuracy - {accuracy_score(data_test['anomaly'], data_test['anomaly_svm'])*100:0.2f}%\")\n",
        "print(f\"precision - {precision_score(data_test['anomaly'], data_test['anomaly_svm'], average='binary')*100:0.2f}%\")\n",
        "print(f\"recall - {recall_score(data_test['anomaly'], data_test['anomaly_svm'], average='binary')*100:0.2f}%\")\n",
        "print(f\"F1 - {f1_score(data_test['anomaly'], data_test['anomaly_svm'], average='binary')*100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "185591fe-cd30-4e1a-8f47-a4de0820cc35",
      "metadata": {
        "id": "185591fe-cd30-4e1a-8f47-a4de0820cc35"
      },
      "source": [
        "Значения метрик **зависят от конкретной задачи** и требований бизнеса. Однако есть **общие рекомендации**:\n",
        "\n",
        "| Метрика  | Хорошее значение  | Плохое значение |\n",
        "|----------|------------------|----------------|\n",
        "| **Accuracy**  | **> 90%** (если классы сбалансированы) | < 50% (хуже случайного угадывания) |\n",
        "| **Precision** | **> 80%** (если важно минимизировать FP) | < 50% (слишком много ложных срабатываний) |\n",
        "| **Recall**    | **> 80%** (если важно минимизировать FN) | < 50% (пропускаем слишком много важных случаев) |\n",
        "| **F1-score**  | **> 70-80%** (если баланс precision/recall важен) | < 50% (модель плохо работает) |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6061002d-8eb9-4788-8760-110be564af3d",
      "metadata": {
        "id": "6061002d-8eb9-4788-8760-110be564af3d"
      },
      "source": [
        "Метод **`score_samples(X)`** в **One-Class SVM** вычисляет **оценку аномальности** (или аффинности) для каждого объекта в `X`.  \n",
        "Чем **ниже** значение, тем **больше вероятность**, что объект **аномальный**.  \n",
        "\n",
        "---\n",
        "\n",
        "One-Class SVM использует **ядровое пространство** для разделения данных.  \n",
        "Метод `score_samples(X)` возвращает **оценку расстояния** от точки `X` до **границы \"нормальности\"**, определенной моделью.  \n",
        "\n",
        "**Чем ниже `score_samples`, тем объект дальше от \"нормы\".**  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Как интерпретировать `score_samples`?**\n",
        "- **Высокие значения (`>0`)** → объект похож на нормальные данные.  \n",
        "- **Низкие значения (`<0`)** → объект аномальный.  \n",
        "- **Граница аномалий находится около `decision_function(X) = 0`**.  \n",
        "\n",
        "Если нужно определить **фактические аномалии**, следует использовать `decision_function(X)` или `predict(X)`.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "| Метод | Что делает? | Когда использовать? |\n",
        "|--------|------------|---------------------|\n",
        "| **`score_samples(X)`** | Возвращает **сырую оценку аномальности** (может быть больше или меньше 0). | Когда нужна **непрерывная шкала аномальности**. |\n",
        "| **`decision_function(X)`** | Возвращает **разницу между `score_samples` и порогом `rho`** (0 - граница нормы). | Когда надо **точно определить, аномалия это или нет**. |\n",
        "\n",
        "`score_samples` полезен, если небходимо **ранжировать аномалии**, а `decision_function`, если еще нужно разделить на **норма/аномалия**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XLdhteZJo6_6",
      "metadata": {
        "id": "XLdhteZJo6_6"
      },
      "outputs": [],
      "source": [
        "data_test.loc[:,'svm_score'] = ocsvm.score_samples(X_test)\n",
        "data_test.loc[:,'svm_decision_function'] = ocsvm.decision_function(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vPFMbRF_pS2G",
      "metadata": {
        "id": "vPFMbRF_pS2G"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure();\n",
        "\n",
        "signal = 'svm_score'\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly'] == 1][signal].index,\n",
        "    data_test[data_test['anomaly'] == 1][signal].values,\n",
        "    s=70, facecolors='none', edgecolors='r',\n",
        "    label= \"Аномальные данные\", alpha=0.5);\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly_svm'] == 1][signal].index,\n",
        "    data_test[data_test['anomaly_svm'] == 1][signal].values,\n",
        "    s=10, facecolors='r', edgecolors='r',\n",
        "    label= \"Выявлена аномалия\", alpha=0.5);\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly'] == 0][signal].index,\n",
        "    data_test[data_test['anomaly'] == 0][signal].values,\n",
        "    s=70, facecolors='none', edgecolors='g',\n",
        "    label= \"Нормальные данные\", alpha=0.5);\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly_svm'] == 0][signal].index,\n",
        "    data_test[data_test['anomaly_svm'] == 0][signal].values,\n",
        "    s=10, facecolors='g', edgecolors='g',\n",
        "    label= \"Не выявлена аномалия\", alpha=0.5);\n",
        "\n",
        "# plt.plot(data_test.index,\n",
        "#          np.ones(data_test.shape[0])*100, color='red', linewidth=5);\n",
        "\n",
        "plt.ylabel(signal, fontsize=20);\n",
        "plt.legend(prop={'size': 16}, loc='lower right');\n",
        "\n",
        "# fig.savefig('fig10.png', dpi=fig.dpi, bbox_inches='tight');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kbsdSxGs428c",
      "metadata": {
        "id": "kbsdSxGs428c"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure();\n",
        "\n",
        "signal = 'svm_decision_function'\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly'] == 1][signal].index,\n",
        "    data_test[data_test['anomaly'] == 1][signal].values,\n",
        "    s=70, facecolors='none', edgecolors='r',\n",
        "    label= \"Аномальные данные\", alpha=0.5);\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly_svm'] == 1][signal].index,\n",
        "    data_test[data_test['anomaly_svm'] == 1][signal].values,\n",
        "    s=10, facecolors='r', edgecolors='r',\n",
        "    label= \"Выявлена аномалия\", alpha=0.5);\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly'] == 0][signal].index,\n",
        "    data_test[data_test['anomaly'] == 0][signal].values,\n",
        "    s=70, facecolors='none', edgecolors='g',\n",
        "    label= \"Нормальные данные\", alpha=0.5);\n",
        "\n",
        "plt.scatter(\n",
        "    data_test[data_test['anomaly_svm'] == 0][signal].index,\n",
        "    data_test[data_test['anomaly_svm'] == 0][signal].values,\n",
        "    s=10, facecolors='g', edgecolors='g',\n",
        "    label= \"Не выявлена аномалия\", alpha=0.5);\n",
        "\n",
        "# plt.plot(data_test.index,\n",
        "#          np.ones(data_test.shape[0])*100, color='red', linewidth=5);\n",
        "\n",
        "plt.ylabel(signal, fontsize=20);\n",
        "plt.legend(prop={'size': 16}, loc='lower right');\n",
        "\n",
        "# fig.savefig('fig10.png', dpi=fig.dpi, bbox_inches='tight');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bdef079-f4a9-4fa4-b896-0b4f1beb2d65",
      "metadata": {
        "id": "7bdef079-f4a9-4fa4-b896-0b4f1beb2d65"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P8d_SAnQK7Yo",
      "metadata": {
        "id": "P8d_SAnQK7Yo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1370284-8723-43a9-90bd-d1709dfe611f",
      "metadata": {
        "id": "c1370284-8723-43a9-90bd-d1709dfe611f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}