{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtyomShabunin/SMOPA-25/blob/main/lesson_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z5j2VAdodu7n",
      "metadata": {
        "id": "z5j2VAdodu7n"
      },
      "source": [
        "<img src=\"https://prana-system.com/files/110/rds_color_full.png\" alt=\"tot image\" width=\"300\"  align=\"center\"/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src=\"https://mpei.ru/AboutUniverse/OficialInfo/Attributes/PublishingImages/logo1.jpg\" alt=\"mpei image\" width=\"200\" align=\"center\"/>\n",
        "<img src=\"https://mpei.ru/Structure/Universe/tanpe/structure/tfhe/PublishingImages/tot.png\" alt=\"tot image\" width=\"100\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "# **Системы машинного обучения и предиктивной аналитики в тепловой и возобновляемой энергетике**  \n",
        "\n",
        "# ***Практические занятия***\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaf3c0bb-0a6c-4518-83e1-0db581e00166",
      "metadata": {
        "id": "eaf3c0bb-0a6c-4518-83e1-0db581e00166"
      },
      "source": [
        "# Занятие №11\n",
        "# Задача регрессии, на примере определения расхода потребляемого топлива на ТЭЦ\n",
        "# PyTorch Lightning\n",
        "**23 апреля 2025г.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KjJa_OrbfhKC",
      "metadata": {
        "id": "KjJa_OrbfhKC"
      },
      "source": [
        "Задача **регрессии** — это тип задачи машинного обучения, в которой модель предсказывает **непрерывное числовое значение** на основе входных данных.\n",
        "\n",
        "Примеры задач регрессии:\n",
        "- Предсказание температуры воздуха по времени суток, влажности и скорости ветра.\n",
        "- Оценка стоимости недвижимости по характеристикам (площадь, этаж, район и т.п.).\n",
        "- Прогнозирование выработки электроэнергии турбиной по текущим параметрам работы.\n",
        "- Прогнозирование вещественного числа на основании предыдущих значений (прогноз потребления электроэнергии)\n",
        "\n",
        "**Формально:**  \n",
        "Если входные данные обозначить как $ X $, а целевое значение как $ y $, то задача регрессии — найти функцию $ f $, такую что:\n",
        "$$ y = f(X) + \\varepsilon, $$\n",
        "где $ \\varepsilon $ — шум (ошибка), а $ y $ — непрерывная величина (например, вещественное число).\n",
        "\n",
        "**В отличие от классификации**, где ответ — это метка (например, \"да\"/\"нет\", \"норма\"/\"авария\"), в регрессии результат — число, которое может принимать бесконечное множество значений.\n",
        "\n",
        "Если модель предсказывает вектор непрерывных чисел, это всё ещё задача регрессии, просто в многомерной форме. Это называется **Многомерная регрессия (Multivariate Regression)** или **Мультиаутпут регрессия (Multi-output Regression)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c3bdc1-d726-4c0c-bf96-d19752222456",
      "metadata": {
        "id": "d8c3bdc1-d726-4c0c-bf96-d19752222456"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import callbacks, cli_lightning_logo, LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.loggers.mlflow import MLFlowLogger\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\", font_scale=1.4)\n",
        "\n",
        "torch.manual_seed(42);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd9fe19e-c440-458e-aa5c-453a4d06b20b",
      "metadata": {
        "id": "bd9fe19e-c440-458e-aa5c-453a4d06b20b"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7759mRs8ksT7",
      "metadata": {
        "id": "7759mRs8ksT7"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "gdown.download('https://drive.google.com/uc?id=17YX6P0YMTx12oNVPcuwGAQgKLOkA5Efy', verify=False)\n",
        "gdown.download('https://drive.google.com/uc?id=17_utMiYF01v1eDJeqkua8JNDzlQ6_pBe', verify=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c65089-ae95-4734-a5b0-c63a1bf6f96d",
      "metadata": {
        "id": "28c65089-ae95-4734-a5b0-c63a1bf6f96d"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"turbohackathon_task2_df1.csv\", parse_dates=[\"data\"], index_col=\"data\")\n",
        "df2 = pd.read_csv(\"turbohackathon_task2_df2.csv\", parse_dates=[\"date\"], index_col=\"date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ka5uhhxLlFue",
      "metadata": {
        "id": "Ka5uhhxLlFue"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n8-yNqUHpwjL",
      "metadata": {
        "id": "n8-yNqUHpwjL"
      },
      "outputs": [],
      "source": [
        "df1.info();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3mgSZF5ZlapC",
      "metadata": {
        "id": "3mgSZF5ZlapC"
      },
      "outputs": [],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IfX_DZ8wp6fy",
      "metadata": {
        "id": "IfX_DZ8wp6fy"
      },
      "outputs": [],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xvoF6DqUl_AY",
      "metadata": {
        "id": "xvoF6DqUl_AY"
      },
      "source": [
        "## Постановка задачи\n",
        "\n",
        "По заданному составу основного оборудования (турбогенераторы, паровые и водогрейные котлы) и значениям суммарной электрической и тепловой нагрузок ТЭЦ определить расход потребляемого топлива и распределение электрической нагрузки по агрегатам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d91eaf-602c-4e2d-a8c8-735055215f31",
      "metadata": {
        "id": "b2d91eaf-602c-4e2d-a8c8-735055215f31"
      },
      "outputs": [],
      "source": [
        "# Удалим данные когда оборудование работало не полные сутки,\n",
        "# чтобы исключить пусковые потери\n",
        "\n",
        "df2 = df2[df2['TG9'] != 2]\n",
        "df2 = df2[df2['TG5'] != 2]\n",
        "df2 = df2[df2['TG4'] != 2]\n",
        "df2 = df2[df2['TG6'] != 2]\n",
        "df2 = df2[df2['TG10'] != 2]\n",
        "df2 = df2[df2['WB'] != 2]\n",
        "\n",
        "df2 = df2[df2['SB4'] != 2]\n",
        "df2 = df2[df2['SB5'] != 2]\n",
        "df2 = df2[df2['SB6'] != 2]\n",
        "df2 = df2[df2['SB8'] != 2]\n",
        "df2 = df2[df2['SB9'] != 2]\n",
        "df2 = df2[df2['SB10'] != 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "930cc146-293d-48d3-b821-20c8597c032c",
      "metadata": {
        "id": "930cc146-293d-48d3-b821-20c8597c032c"
      },
      "outputs": [],
      "source": [
        "# Приведем датафреймы к одно дискретизации и объединим их\n",
        "\n",
        "df = pd.concat([df2, df1.resample('1d').mean().loc[df2.index,:]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eJjy2Sa_nxZj",
      "metadata": {
        "id": "eJjy2Sa_nxZj"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9d1002-d966-4177-80cb-179f54a0eedb",
      "metadata": {
        "id": "af9d1002-d966-4177-80cb-179f54a0eedb"
      },
      "source": [
        "## Анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de685878-c56d-4e33-b20b-6f299e9c0550",
      "metadata": {
        "id": "de685878-c56d-4e33-b20b-6f299e9c0550"
      },
      "source": [
        "Проверим баланс электроэнергии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594020d2-dba7-4a12-8307-ae273d6fff76",
      "metadata": {
        "id": "594020d2-dba7-4a12-8307-ae273d6fff76"
      },
      "outputs": [],
      "source": [
        "(df['TG4_kWhr'] + df['TG5_kWhr'] + df['TG6_kWhr'] + df['TG9_kWhr'] + df['TG10_kWhr'] - df['sum_kWhr']).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d8afb9-c327-485c-8f7c-9462b290a4fa",
      "metadata": {
        "id": "85d8afb9-c327-485c-8f7c-9462b290a4fa"
      },
      "source": [
        "Определим все комбинации ТГ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32882c00-1da2-4a5d-91ec-e605f3976bc3",
      "metadata": {
        "id": "32882c00-1da2-4a5d-91ec-e605f3976bc3"
      },
      "outputs": [],
      "source": [
        "tg_columns = [\"TG4\", \"TG5\", \"TG6\", \"TG9\", \"TG10\"]\n",
        "\n",
        "tg_combinations = df[tg_columns].apply(\n",
        "    lambda row: ''.join([col for col in tg_columns if row[col]]),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NYHn2bS5oecl",
      "metadata": {
        "id": "NYHn2bS5oecl"
      },
      "outputs": [],
      "source": [
        "# tg_combinations.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98cd888a-f8dc-41f8-8256-9081926a6e51",
      "metadata": {
        "id": "98cd888a-f8dc-41f8-8256-9081926a6e51"
      },
      "source": [
        "Дополним комбинации ТГ водогрейным котлов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa65f209-7102-4014-be70-18d835848de5",
      "metadata": {
        "id": "aa65f209-7102-4014-be70-18d835848de5"
      },
      "outputs": [],
      "source": [
        "tg_wb_columns = tg_columns + [\"WB\"]\n",
        "\n",
        "tg_wb_combinations = df[tg_wb_columns].apply(\n",
        "    lambda row: ''.join([col for col in tg_wb_columns if row[col]]),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0lSvpNAhK4Js",
      "metadata": {
        "id": "0lSvpNAhK4Js"
      },
      "source": [
        "Комбинации всего основного оборудования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KP9tSGV_KzLH",
      "metadata": {
        "id": "KP9tSGV_KzLH"
      },
      "outputs": [],
      "source": [
        "tg_wb_sb_columns = tg_wb_columns + [\"SB4\", \"SB5\", \"SB6\", \"SB8\", \"SB9\", \"SB10\"]\n",
        "\n",
        "tg_wb_sb_combinations = df[tg_wb_sb_columns].apply(\n",
        "    lambda row: ''.join([col for col in tg_wb_sb_columns if row[col]]),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0819914-9896-41ee-a954-407baa3366e7",
      "metadata": {
        "id": "c0819914-9896-41ee-a954-407baa3366e7"
      },
      "outputs": [],
      "source": [
        "df['tg_combinations'] = tg_combinations\n",
        "df['tg_wb_combinations'] = tg_wb_combinations\n",
        "df['tg_wb_sb_combinations'] = tg_wb_sb_combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cv9P_avoL7MD",
      "metadata": {
        "id": "cv9P_avoL7MD"
      },
      "outputs": [],
      "source": [
        "print(df[\"tg_combinations\"].unique().shape[0])\n",
        "print(df[\"tg_combinations\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UzylrgwIMAxS",
      "metadata": {
        "id": "UzylrgwIMAxS"
      },
      "outputs": [],
      "source": [
        "print(df[\"tg_wb_combinations\"].unique().shape[0])\n",
        "print(df[\"tg_wb_combinations\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tI_BNBVzMBdF",
      "metadata": {
        "id": "tI_BNBVzMBdF"
      },
      "outputs": [],
      "source": [
        "print(df[\"tg_wb_sb_combinations\"].unique().shape[0])\n",
        "print(df[\"tg_wb_sb_combinations\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UQG4Jk46r0Zq",
      "metadata": {
        "id": "UQG4Jk46r0Zq"
      },
      "source": [
        "## Выделение признаков и целевых значений"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RmRwAsE2sJo6",
      "metadata": {
        "id": "RmRwAsE2sJo6"
      },
      "source": [
        "Вспомогательная функция для масштабирования данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7669ded8-d319-4f9b-90e3-ef87b480f5c3",
      "metadata": {
        "id": "7669ded8-d319-4f9b-90e3-ef87b480f5c3"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "def trnsfrm(x, scale: bool, norm: bool) -> Tuple[np.ndarray, dict]:\n",
        "    \"\"\"\n",
        "    Transforms the input data using either StandardScaler or MinMaxScaler based on user input.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input data as a numpy array.\n",
        "        scale (bool): Flag to apply StandardScaler.\n",
        "        norm (bool): Flag to apply MinMaxScaler.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, Dict]: Tuple containing the transformed data as a numpy array and a dictionary with information on the applied scaler (mean and standard deviation for StandardScaler, and minimum and maximum values for MinMaxScaler).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    xx = x.copy()\n",
        "    s = StandardScaler()\n",
        "    n = MinMaxScaler()\n",
        "    info = {}\n",
        "    if scale:\n",
        "        xx = s.fit_transform(xx)\n",
        "        info['scale'] = {\"mean\": s.mean_.tolist(),\n",
        "                         \"std\": s.scale_.tolist()}\n",
        "    elif norm:\n",
        "        xx = n.fit_transform(xx)\n",
        "        info['norm'] = {\"min_\": n.data_min_.tolist(),\n",
        "                        \"max_\": n.data_max_.tolist()}\n",
        "    return s, n, xx, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33a99b2-d7cf-46d8-b159-84ed20361745",
      "metadata": {
        "id": "c33a99b2-d7cf-46d8-b159-84ed20361745"
      },
      "outputs": [],
      "source": [
        "x_labels = ['sum_kWhr', 'Q_gcalhr', 'tamb',\n",
        "            's10ata_tonhr', 's16ata_tonhr', 's30ata_tonhr',\n",
        "            'TG4', 'TG5', 'TG6', 'TG9', 'TG10',\n",
        "            'SB4', 'SB5', 'SB6', 'SB8', 'SB9', 'SB10',\n",
        "            'WB',]\n",
        "y_labels = ['TG4_kWhr', 'TG5_kWhr', 'TG6_kWhr',\n",
        "            'TG9_kWhr', 'TG10_kWhr', 'B_1e3m3']\n",
        "\n",
        "X = df.loc[:, x_labels]\n",
        "y = df.loc[:, y_labels]\n",
        "\n",
        "X = X.values.astype(\"float32\")\n",
        "y = y.values.astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AdsH6AQpuC2n",
      "metadata": {
        "id": "AdsH6AQpuC2n"
      },
      "source": [
        "Масштабирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BGggyGJWsyHZ",
      "metadata": {
        "id": "BGggyGJWsyHZ"
      },
      "outputs": [],
      "source": [
        "s_X, n_X, X, prep_x_info = trnsfrm(X,\n",
        "            scale=False,\n",
        "            norm=True)\n",
        "# prep_x_info['scale_x'] = prep_x_info.pop('scale')\n",
        "\n",
        "\n",
        "s_y, n_y, y, prep_y_info = trnsfrm(y,\n",
        "            scale=False,\n",
        "            norm=True)\n",
        "# prep_y_info['scale_y'] = prep_y_info.pop('scale')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E91yZZuRCBBZ",
      "metadata": {
        "id": "E91yZZuRCBBZ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "topXIcrJCBVn",
      "metadata": {
        "id": "topXIcrJCBVn"
      },
      "outputs": [],
      "source": [
        "class PPDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.X = torch.tensor(X, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qQUCsSawC_u6",
      "metadata": {
        "id": "qQUCsSawC_u6"
      },
      "source": [
        "Разделение на обучающую и тестовую части"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iOlrmyrYCbT0",
      "metadata": {
        "id": "iOlrmyrYCbT0"
      },
      "outputs": [],
      "source": [
        "dataset = PPDataset()\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q8B6iW2uvePj",
      "metadata": {
        "id": "Q8B6iW2uvePj"
      },
      "source": [
        "## PyTorch Lightning\n",
        "**PyTorch Lightning** — это **высокоуровневая обёртка над PyTorch**, которая помогает писать чище и структурированнее код для обучения нейросетей, не теряя гибкости самого PyTorch.\n",
        "\n",
        "Зачем нужен PyTorch Lightning?\n",
        "При использовании \"чистого\" PyTorch, часто получается куча повторяющегося кода:\n",
        "- обучение (`train`),\n",
        "- валидация,\n",
        "- переключение между режимами `.train()` и `.eval()` и т.д.\n",
        "\n",
        "**Lightning берёт это на себя**, позволяя сосредоточиться только на логике модели.\n",
        "\n",
        "---\n",
        "\n",
        "**Основные плюсы:**\n",
        "\n",
        "**Чистый и модульный код**  \n",
        "   Всё разбито на понятные методы: `forward()`, `training_step()`, `configure_optimizers()`, и т.д."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cTz_H1QAuIyK",
      "metadata": {
        "id": "cTz_H1QAuIyK"
      },
      "source": [
        "### Полносвязная нейронная сеть\n",
        "\n",
        "\n",
        "### `class FCNN(LightningModule)`\n",
        "Это реализация **полносвязной нейронной сети (Fully Connected Neural Network, FCNN)** для задачи регрессии или прогнозирования с использованием **PyTorch Lightning**.\n",
        "\n",
        "---\n",
        "\n",
        "### `__init__`\n",
        "**Аргументы конструктора:**\n",
        "- `input_features` — количество входных признаков.\n",
        "- `output_features` — размер выходного вектора.\n",
        "- `hidden_dim` — размер скрытых слоёв (по умолчанию 32).\n",
        "- `hidden_num` — количество скрытых слоёв (по умолчанию 3).\n",
        "- `lr` — скорость обучения (learning rate).\n",
        "\n",
        "**Что делает:**\n",
        "- Сохраняет параметры.\n",
        "- Создаёт список скрытых линейных слоёв (`nn.Linear`) в `nn.ModuleList`.\n",
        "  - Первый слой соединяет вход с первым скрытым слоем.\n",
        "  - Остальные соединяют скрытые слои между собой.\n",
        "- Создаёт выходной слой (`self.out`) — последний линейный слой, выдающий предсказание.\n",
        "- `example_input_array` нужен для экспорта модели и визуализации.\n",
        "\n",
        "---\n",
        "\n",
        "### `forward(self, x)`\n",
        "**Что делает:**\n",
        "- Последовательно применяет к входу `x` скрытые слои с активацией ReLU.\n",
        "- Затем применяет выходной линейный слой.\n",
        "- Возвращает результат (`y_hat`).\n",
        "\n",
        "---\n",
        "\n",
        "### `training_step(self, batch, batch_idx)`\n",
        "- Обрабатывает один батч на тренировке.\n",
        "- Вызывает `_common_step`, где рассчитывается MSE loss.\n",
        "- Логирует значение ошибки (`train_loss`).\n",
        "\n",
        "---\n",
        "\n",
        "### `validation_step(self, batch, batch_idx)`\n",
        "- То же, что `training_step`, но на валидации.\n",
        "- Логирует `val_loss`.\n",
        "\n",
        "---\n",
        "\n",
        "### `configure_optimizers(self)`\n",
        "- Возвращает оптимизатор Adam с заданной скоростью обучения.\n",
        "\n",
        "---\n",
        "\n",
        "### `_common_step(self, batch, batch_idx, stage: str)`\n",
        "- Унифицированная функция для `training_step` и `validation_step`.\n",
        "- Выполняет forward-pass, считает среднеквадратичную ошибку (`F.mse_loss`), логирует loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebfe58e6-b5be-46d9-b9b3-7bc1f77b0cb6",
      "metadata": {
        "id": "ebfe58e6-b5be-46d9-b9b3-7bc1f77b0cb6"
      },
      "outputs": [],
      "source": [
        "class FCNN(LightningModule):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_features: int,\n",
        "                 output_features: int,\n",
        "                 hidden_dim = 32,\n",
        "                 hidden_num=3,\n",
        "                 lr: float = 1e-3):\n",
        "\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.layers_size = {'input_features': input_features,\n",
        "                            'output_features': output_features,\n",
        "                            'hidden_dim': hidden_dim,\n",
        "                            'hidden_num': hidden_num}\n",
        "\n",
        "        self.lr = lr\n",
        "\n",
        "        self.linear = nn.ModuleList()\n",
        "        self.hidden_num = hidden_num\n",
        "\n",
        "        for i in range(hidden_num):\n",
        "          if i == 0:\n",
        "            self.linear.append(nn.Linear(input_features, hidden_dim))\n",
        "          else:\n",
        "            self.linear.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "        self.out = nn.Linear(hidden_dim, output_features)\n",
        "\n",
        "        self.example_input_array = torch.randn(1, input_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "      for i in range(self.hidden_num):\n",
        "        x = F.relu(self.linear[i](x))\n",
        "\n",
        "      y_hat = self.out(x)\n",
        "      return y_hat\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._common_step(batch, batch_idx, \"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._common_step(batch, batch_idx, \"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def _common_step(self, batch, batch_idx, stage: str):\n",
        "        x, y = batch\n",
        "        x = x.to(torch.float32)\n",
        "        y = y.to(torch.float32)\n",
        "        y_hat = self(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "\n",
        "        if stage == \"train\":\n",
        "          self.log(f\"{stage}_loss\", loss, on_step=True, on_epoch=True)\n",
        "        else:  # val\n",
        "          self.log(f\"{stage}_loss\", loss, on_step=False, on_epoch=True)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_IB4jgpcDvrQ",
      "metadata": {
        "id": "_IB4jgpcDvrQ"
      },
      "source": [
        "### EarlyStopping (ранняя остановка)\n",
        "Используется для предотвращения переобучения — остановка обучения, когда модель перестаёт улучшаться."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3102ff2b-f68b-43a4-8761-b1e2b90e2f09",
      "metadata": {
        "id": "3102ff2b-f68b-43a4-8761-b1e2b90e2f09"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "e_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",      # Следим за значением val_loss\n",
        "    min_delta=0.001,         # Минимальное улучшение, чтобы считать его значимым\n",
        "    patience=3,              # Остановится, если 3 эпохи подряд нет улучшения\n",
        "    verbose=False,           # Не печатает логи в консоль (можно включить True)\n",
        "    mode=\"min\"               # Чем меньше val_loss — тем лучше\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54kLX6-FGRDr",
      "metadata": {
        "id": "54kLX6-FGRDr"
      },
      "source": [
        "### ModelCheckpoint\n",
        "\n",
        "Сохраняет чекпоинты по ходу обучения, чтобы потом можно было:\n",
        "- восстановить лучшую модель;\n",
        "- продолжить обучение;\n",
        "- делать инференс."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e63b8e2-4536-4193-90e8-41670ebe8024",
      "metadata": {
        "id": "1e63b8e2-4536-4193-90e8-41670ebe8024"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoints_dir = './runs'\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=checkpoints_dir,                      # Папка, куда сохраняются модели\n",
        "    monitor='train_loss',                         # Метрика, по которой выбираются лучшие модели\n",
        "    filename=\"sample-{epoch:02d}-{train_loss:.2f}-{val_loss:.2f}\",  # Имя файла с шаблоном\n",
        "    save_top_k=5,                                 # Хранить только 5 лучших моделей\n",
        "    save_weights_only=False                       # Сохранять всю модель, не только веса\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26H-t9SfJ8gD",
      "metadata": {
        "id": "26H-t9SfJ8gD"
      },
      "source": [
        "### Trainer\n",
        "Trainer — основной объект, который управляет всем процессом обучения: эпохи, батчи, GPU, логирование, чекпоинты, callbacks и т.д."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d10c1eb-8103-4c02-af59-fafae7df03eb",
      "metadata": {
        "id": "9d10c1eb-8103-4c02-af59-fafae7df03eb"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import CSVLogger\n",
        "\n",
        "logger = CSVLogger(\"logs\", name=\"my_model\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    logger=logger,\n",
        "    devices=\"auto\",                      # Автоматически выбрать устройство (GPU/CPU)\n",
        "    accelerator=\"auto\",                  # Автоматически определить тип ускорителя (cuda, mps, tpu и т.д.)\n",
        "    log_every_n_steps=2,                 # Частота логирования\n",
        "    max_epochs=100,                      # Максимум 100 эпох\n",
        "    enable_checkpointing=True,          # Включить сохранение моделей\n",
        "    default_root_dir=checkpoints_dir,   # Корень для логов и чекпоинтов\n",
        "    callbacks=[e_stop, checkpoint_callback]  # Список callback-ов\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b-qmNJO1LLm3",
      "metadata": {
        "id": "b-qmNJO1LLm3"
      },
      "source": [
        "## Инициализация и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739f611c-94bc-4dca-9558-e1586594a4ba",
      "metadata": {
        "id": "739f611c-94bc-4dca-9558-e1586594a4ba"
      },
      "outputs": [],
      "source": [
        "params_info = {'input': x_labels,\n",
        "               'output': y_labels}\n",
        "\n",
        "input_features = X.shape[-1]\n",
        "output_features = y.shape[-1]\n",
        "hidden_dim = 32\n",
        "hidden_num = 3\n",
        "learning_rate = 1e-3\n",
        "\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d178a37-6e1f-4a84-a12a-3e2450a9f71a",
      "metadata": {
        "id": "8d178a37-6e1f-4a84-a12a-3e2450a9f71a"
      },
      "outputs": [],
      "source": [
        "model = FCNN(\n",
        "    input_features=input_features,\n",
        "    output_features=output_features,\n",
        "    hidden_dim=hidden_dim,\n",
        "    hidden_num=hidden_num,\n",
        "    lr=learning_rate)\n",
        "model_layers = {'layers': model.layers_size}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3db86ed0-f13a-4ed4-a768-f3f46059ec40",
      "metadata": {
        "id": "3db86ed0-f13a-4ed4-a768-f3f46059ec40"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f816755b-cf10-43b9-8233-b22748a1ccdd",
      "metadata": {
        "id": "f816755b-cf10-43b9-8233-b22748a1ccdd"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55UrcbUudJIc",
      "metadata": {
        "id": "55UrcbUudJIc"
      },
      "source": [
        "## Анализ обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f8aefa5-2f58-4d20-b008-c7c056b91fdf",
      "metadata": {
        "id": "9f8aefa5-2f58-4d20-b008-c7c056b91fdf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "log_df = pd.read_csv(\"logs/my_model/version_0/metrics.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EHXJlWTTOWK5",
      "metadata": {
        "id": "EHXJlWTTOWK5"
      },
      "outputs": [],
      "source": [
        "log_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AQNfJeD2RZ3p",
      "metadata": {
        "id": "AQNfJeD2RZ3p"
      },
      "outputs": [],
      "source": [
        "plt.plot(\n",
        "    log_df['epoch'], log_df['train_loss_epoch'],\n",
        "    linestyle='none', marker='.', markersize=5,\n",
        "    label='train')\n",
        "\n",
        "plt.plot(\n",
        "    log_df['epoch'], log_df['val_loss'],\n",
        "    linestyle='none', marker='.', markersize=5,\n",
        "    label='val');\n",
        "\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae191b4-4825-4b4b-92b4-6d9f766c6f9f",
      "metadata": {
        "id": "2ae191b4-4825-4b4b-92b4-6d9f766c6f9f"
      },
      "outputs": [],
      "source": [
        "trainer.logged_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка модели из чекпоинта"
      ],
      "metadata": {
        "id": "rUfYvrirWu4C"
      },
      "id": "rUfYvrirWu4C"
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'runs/sample-epoch=63-train_loss=0.02-val_loss=0.01.ckpt'\n",
        "model_ckpt = FCNN.load_from_checkpoint(checkpoint_path)\n",
        "model_ckpt.eval()"
      ],
      "metadata": {
        "id": "yc_6UvNzW0PU"
      },
      "id": "yc_6UvNzW0PU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dFcwpIw3kRyM",
      "metadata": {
        "id": "dFcwpIw3kRyM"
      },
      "source": [
        "## Определим границы каждого возможного состава оборудования"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ex = df.sample()[x_labels]\n",
        "x_ex"
      ],
      "metadata": {
        "id": "wSCMUofTY1kq"
      },
      "id": "wSCMUofTY1kq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    n_y.inverse_transform(model_ckpt(torch.tensor(n_X.transform(x_ex.values), dtype=torch.float32)).detach().numpy()),\n",
        "    columns=y_labels)"
      ],
      "metadata": {
        "id": "BmHqQn5YY1tj"
      },
      "id": "BmHqQn5YY1tj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ex = np.array([[1.904085e+05, 8.937500e+01, 1.070000e+01, 2.650000e+02,\n",
        "                  1.020000e+02, 4.600000e+01, 0.000000e+00, 1.000000e+00,\n",
        "                  1.000000e+00, 1.000000e+00, 0.000000e+00,\n",
        "                  0, 0, 0, 0, 0, 0, 0]])"
      ],
      "metadata": {
        "id": "kk9yybw4mTiB"
      },
      "id": "kk9yybw4mTiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(x_ex, columns=x_labels)"
      ],
      "metadata": {
        "id": "uHr_V9pKjiCw"
      },
      "id": "uHr_V9pKjiCw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    n_y.inverse_transform(model_ckpt(torch.tensor(n_X.transform(x_ex), dtype=torch.float32)).detach().numpy()),\n",
        "    columns=y_labels)"
      ],
      "metadata": {
        "id": "gmPCAg70jiF5"
      },
      "id": "gmPCAg70jiF5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы учесть технологические ограничения определим границы всех варинатов состава ТГ которые есть в данных"
      ],
      "metadata": {
        "id": "4Cs1XmHrthVf"
      },
      "id": "4Cs1XmHrthVf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZxjK-8Ufj0g7",
      "metadata": {
        "id": "ZxjK-8Ufj0g7"
      },
      "outputs": [],
      "source": [
        "power_max = df[['tg_wb_combinations', 'sum_kWhr']].groupby('tg_wb_combinations').max()\n",
        "power_max.columns = ['power_kW_max']\n",
        "power_min = df[['tg_wb_combinations', 'sum_kWhr']].groupby('tg_wb_combinations').min()\n",
        "power_min.columns = ['power_kW_min']\n",
        "\n",
        "s30ata_tonhr_max = df[['tg_wb_combinations', 's30ata_tonhr']].groupby('tg_wb_combinations').max()\n",
        "s30ata_tonhr_max.columns = ['s30ata_tonhr_max']\n",
        "s30ata_tonhr_min = df[['tg_wb_combinations', 's30ata_tonhr']].groupby('tg_wb_combinations').min()\n",
        "s30ata_tonhr_min.columns = ['s30ata_tonhr_min']\n",
        "\n",
        "s16ata_tonhr_max = df[['tg_wb_combinations', 's16ata_tonhr']].groupby('tg_wb_combinations').max()\n",
        "s16ata_tonhr_max.columns = ['s16ata_tonhr_max']\n",
        "s16ata_tonhr_min = df[['tg_wb_combinations', 's16ata_tonhr']].groupby('tg_wb_combinations').min()\n",
        "s16ata_tonhr_min.columns = ['s16ata_tonhr_min']\n",
        "\n",
        "s10ata_tonhr_max = df[['tg_wb_combinations', 's10ata_tonhr']].groupby('tg_wb_combinations').max()\n",
        "s10ata_tonhr_max.columns = ['s10ata_tonhr_max']\n",
        "s10ata_tonhr_min = df[['tg_wb_combinations', 's10ata_tonhr']].groupby('tg_wb_combinations').min()\n",
        "s10ata_tonhr_min.columns = ['s10ata_tonhr_min']\n",
        "\n",
        "Q_max = df[['tg_wb_combinations', 'Q_gcalhr']].groupby('tg_wb_combinations').max()\n",
        "Q_max.columns = ['Q_max']\n",
        "Q_min = df[['tg_wb_combinations', 'Q_gcalhr']].groupby('tg_wb_combinations').min()\n",
        "Q_min.columns = ['Q_min']\n",
        "\n",
        "one_hot = df[['tg_wb_combinations', 'TG4', 'TG5', 'TG6', 'TG9', 'TG10', 'WB']].groupby('tg_wb_combinations').mean()\n",
        "\n",
        "eq_table = pd.concat([\n",
        "    power_max, power_min,\n",
        "    s30ata_tonhr_max, s30ata_tonhr_min,\n",
        "    s16ata_tonhr_max, s16ata_tonhr_min,\n",
        "    s10ata_tonhr_max, s10ata_tonhr_min,\n",
        "    Q_max, Q_min,\n",
        "    one_hot], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E50Cobscj0jA",
      "metadata": {
        "id": "E50Cobscj0jA"
      },
      "outputs": [],
      "source": [
        "eq_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gMLH14HLmN3A",
      "metadata": {
        "id": "gMLH14HLmN3A"
      },
      "outputs": [],
      "source": [
        "eq_table.to_csv('eq_table.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gdd8EeTXnOeN",
      "metadata": {
        "id": "gdd8EeTXnOeN"
      },
      "outputs": [],
      "source": [
        "all_eq_combinations = df[[\n",
        "    'tg_wb_sb_combinations',\n",
        "    'TG4', 'TG5', 'TG6', 'TG9', 'TG10',\n",
        "    'WB', 'SB4', 'SB5', 'SB6', 'SB8', 'SB9', 'SB10']].groupby('tg_wb_sb_combinations').mean()\n",
        "all_eq_combinations = all_eq_combinations.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wYWfCMmOM9Jj",
      "metadata": {
        "id": "wYWfCMmOM9Jj"
      },
      "outputs": [],
      "source": [
        "all_eq_combinations.to_csv('eq_comb.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sV__GSe7M9ND",
      "metadata": {
        "id": "sV__GSe7M9ND"
      },
      "outputs": [],
      "source": [
        "eq_table"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для получения всех комбинаций оборудования с учетом определенных ограничений"
      ],
      "metadata": {
        "id": "rgKubExXwfrg"
      },
      "id": "rgKubExXwfrg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yWFVW-RwoJYj",
      "metadata": {
        "id": "yWFVW-RwoJYj"
      },
      "outputs": [],
      "source": [
        "def available_combinations(\n",
        "    heat_load, power, steam10, steam16, steam30,\n",
        "    tg4, tg5, tg6, tg9, tg10, wb,\n",
        "    sb4, sb5, sb6, sb8, sb9, sb10\n",
        "):\n",
        "    # Загрузка исходных данных\n",
        "    raw_df = pd.read_csv(\"eq_table.csv\", index_col=0)\n",
        "    selected_columns = [\n",
        "        'power_kW_max', 'power_kW_min',\n",
        "        's30ata_tonhr_max', 's30ata_tonhr_min',\n",
        "        's16ata_tonhr_max', 's16ata_tonhr_min',\n",
        "        's10ata_tonhr_max', 's10ata_tonhr_min',\n",
        "        'Q_max', 'Q_min',\n",
        "        'TG4', 'TG5', 'TG6', 'TG9', 'TG10', 'WB'\n",
        "    ]\n",
        "    df = raw_df[selected_columns].copy()\n",
        "\n",
        "    # Приведение мощности к кВт\n",
        "    power *= 1e3\n",
        "\n",
        "    # Фильтрация по диапазонам нагрузок и расходов пара\n",
        "    factor = 0.1\n",
        "    conditions = (\n",
        "        (df[\"Q_max\"] >= heat_load*(1-factor)) & (df[\"Q_min\"] <= heat_load*(1+factor)) &\n",
        "        (df[\"power_kW_max\"] >= power*(1-factor)) & (df[\"power_kW_min\"] <= power*(1+factor)) &\n",
        "        (df[\"s10ata_tonhr_max\"] >= steam10*(1-factor)) & (df[\"s10ata_tonhr_min\"] <= steam10*(1+factor)) &\n",
        "        (df[\"s16ata_tonhr_max\"] >= steam16*(1-factor)) & (df[\"s16ata_tonhr_min\"] <= steam16*(1+factor)) &\n",
        "        (df[\"s30ata_tonhr_max\"] >= steam30*(1-factor)) & (df[\"s30ata_tonhr_min\"] <= steam30*(1+factor))\n",
        "    )\n",
        "    df = df[conditions]\n",
        "\n",
        "    # Фильтрация по включенным ТГ\n",
        "    for eq_name, is_enabled in zip(['TG4', 'TG5', 'TG6', 'TG9', 'TG10', 'WB'], [tg4, tg5, tg6, tg9, tg10, wb]):\n",
        "        if not is_enabled:\n",
        "            df = df[df[eq_name] == 0]\n",
        "\n",
        "    # Загрузка всех допустимых комбинаций оборудования\n",
        "    eq_comb = pd.read_csv(\"eq_comb.csv\", index_col=0)\n",
        "\n",
        "    if df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    dfs = []\n",
        "    equipment_cols = ['TG4', 'TG5', 'TG6', 'TG9', 'TG10', 'WB']\n",
        "\n",
        "    for idx, row in df[equipment_cols].iterrows():\n",
        "        mask = (eq_comb[equipment_cols] == row).all(axis=1)\n",
        "        dfs.append(eq_comb[mask])\n",
        "\n",
        "    if not dfs:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df_comb = pd.concat(dfs, axis=0)\n",
        "\n",
        "    # Фильтрация по включенным КА\n",
        "    for sb_name, is_enabled in zip(['SB4', 'SB5', 'SB6', 'SB8', 'SB9', 'SB10'], [sb4, sb5, sb6, sb8, sb9, sb10]):\n",
        "        if not is_enabled:\n",
        "            df_comb = df_comb[df_comb[sb_name] == 0]\n",
        "\n",
        "    return df_comb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для получения списка возможных сочетаний оборудования с нагрузкой ТГ и суммарным расходом топлива. Список отсортирован по возрастанию суммарного расхода топлива"
      ],
      "metadata": {
        "id": "0NGyH7pawsSK"
      },
      "id": "0NGyH7pawsSK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9JqMa_94oJeU",
      "metadata": {
        "id": "9JqMa_94oJeU"
      },
      "outputs": [],
      "source": [
        "def get_result(\n",
        "    tamb, heat_load, power,\n",
        "    steam10, steam16, steam30,\n",
        "    tg4, tg5, tg6, tg9, tg10,\n",
        "    sb4, sb5, sb6, sb8, sb9, sb10,\n",
        "    wb\n",
        "):\n",
        "    # Получение всех допустимых комбинаций оборудования\n",
        "    eq_combinations = available_combinations(\n",
        "        heat_load, power, steam10, steam16, steam30,\n",
        "        tg4, tg5, tg6, tg9, tg10, wb,\n",
        "        sb4, sb5, sb6, sb8, sb9, sb10\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    if eq_combinations.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Подготовка исходных признаков\n",
        "    df_features = pd.DataFrame({\n",
        "        'sum_kWhr': [power * 1e3],\n",
        "        'Q_gcalhr': [heat_load],\n",
        "        'tamb': [tamb],\n",
        "        's10ata_tonhr': [steam10],\n",
        "        's16ata_tonhr': [steam16],\n",
        "        's30ata_tonhr': [steam30]\n",
        "    })\n",
        "\n",
        "    # Объединение признаков с комбинациями оборудования\n",
        "    df_features = pd.concat([df_features, eq_combinations], axis=1).ffill()\n",
        "\n",
        "    # Оставляем только нужные колонки в правильном порядке\n",
        "    feature_columns = [\n",
        "        'sum_kWhr', 'Q_gcalhr', 'tamb',\n",
        "        's10ata_tonhr', 's16ata_tonhr', 's30ata_tonhr',\n",
        "        'TG4', 'TG5', 'TG6', 'TG9', 'TG10',\n",
        "        'SB4', 'SB5', 'SB6', 'SB8', 'SB9', 'SB10',\n",
        "        'WB'\n",
        "    ]\n",
        "\n",
        "    df_features = df_features[feature_columns]\n",
        "\n",
        "    # Нормализация признаков\n",
        "    min_x = np.array(prep_x_info['norm']['min_'])\n",
        "    max_x = np.array(prep_x_info['norm']['max_'])\n",
        "    df_features_norm = (df_features - min_x) / (max_x - min_x)\n",
        "\n",
        "    # Прогнозирование\n",
        "    input_tensor = torch.tensor(df_features_norm.values, dtype=torch.float32)\n",
        "    result_norm = model(input_tensor)\n",
        "\n",
        "    # Де-нормализация результатов\n",
        "    min_y = np.array(prep_y_info['norm']['min_'])\n",
        "    max_y = np.array(prep_y_info['norm']['max_'])\n",
        "    result = result_norm.detach().numpy() * (max_y - min_y) + min_y\n",
        "\n",
        "    # Формирование итогового DataFrame\n",
        "    result_df = pd.DataFrame(result, columns=[\n",
        "        'TG4_kWhr', 'TG5_kWhr', 'TG6_kWhr',\n",
        "        'TG9_kWhr', 'TG10_kWhr', 'B_1e3m3'\n",
        "    ])\n",
        "\n",
        "    # Объединение признаков и предсказаний\n",
        "    final_result = pd.concat([df_features, result_df], axis=1)\n",
        "\n",
        "    # Обработка отрицательных значений\n",
        "    final_result[final_result < 0] = 0\n",
        "\n",
        "    # Сортировка по потреблению газа\n",
        "    final_result.sort_values(by='B_1e3m3', inplace=True)\n",
        "    final_result.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    return final_result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param1 = {\n",
        "    'tamb': 15,\n",
        "    'heat_load': 145.88,\n",
        "    'power': 194.34,\n",
        "    'steam10': 250,\n",
        "    'steam16': 105,\n",
        "    'steam30': 37,\n",
        "    'tg4': True,\n",
        "    'tg5': True,\n",
        "    'tg6': True,\n",
        "    'tg9': True,\n",
        "    'tg10': True,\n",
        "    'wb': True,\n",
        "    'sb4': True,\n",
        "    'sb5': True,\n",
        "    'sb6': True,\n",
        "    'sb8': True,\n",
        "    'sb9': True,\n",
        "    'sb10': True\n",
        "}"
      ],
      "metadata": {
        "id": "rJQNGil3I-VQ"
      },
      "id": "rJQNGil3I-VQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = get_result(**param1)"
      ],
      "metadata": {
        "id": "EUjJWF8wXH_I"
      },
      "id": "EUjJWF8wXH_I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "id": "Jj1R7ZposgZK"
      },
      "id": "Jj1R7ZposgZK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "100 * (r[['TG4_kWhr', 'TG5_kWhr', 'TG6_kWhr', 'TG9_kWhr', 'TG10_kWhr']].sum(axis=1) - r['sum_kWhr']) / r['sum_kWhr']"
      ],
      "metadata": {
        "id": "cNPfpS8KJQ2p"
      },
      "id": "cNPfpS8KJQ2p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Анализ режимов эксплуатации с помощью модели"
      ],
      "metadata": {
        "id": "FumNdakfRKos"
      },
      "id": "FumNdakfRKos"
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "eq_columns = [\n",
        "    'TG4', 'TG5', 'TG6', 'TG9', 'TG10',\n",
        "    'SB4', 'SB5', 'SB6', 'SB8', 'SB9', 'SB10', 'WB']\n",
        "tg_columns = ['TG4', 'TG5', 'TG6', 'TG9', 'TG10']\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "  x = {\n",
        "        \"heat_load\": max(0,row['Q_gcalhr']),\n",
        "        \"steam10\": row['s10ata_tonhr'],\n",
        "        \"steam16\": row['s16ata_tonhr'],\n",
        "        \"steam30\": row['s30ata_tonhr'],\n",
        "        \"power\": row['sum_kWhr']*1e-3,\n",
        "        \"tamb\": row['tamb'],\n",
        "        \"tg4\": True,\n",
        "        \"tg5\": True,\n",
        "        \"tg6\": True,\n",
        "        \"tg9\": True,\n",
        "        \"tg10\": True,\n",
        "        \"sb4\": True,\n",
        "        \"sb5\": True,\n",
        "        \"sb6\": True,\n",
        "        \"sb8\": True,\n",
        "        \"sb9\": True,\n",
        "        \"sb10\": True,\n",
        "        \"wb\": True\n",
        "    }\n",
        "\n",
        "  result = get_result(**x)\n",
        "\n",
        "  r = {}\n",
        "\n",
        "  for i, opt in result.iterrows():\n",
        "\n",
        "    if ('actual_opt_position' not in r.keys()) and (\n",
        "        (opt[eq_columns] == row[eq_columns]).all()):\n",
        "      r[\"actual_opt_position\"] = i+1\n",
        "\n",
        "    if ('actual_opt_tg_position' not in r.keys()) and (\n",
        "        (opt[tg_columns] == row[tg_columns]).all()):\n",
        "      r[\"actual_opt_tg_position\"] = i+1\n",
        "\n",
        "  results.append(r)"
      ],
      "metadata": {
        "id": "fEmLIPc-4LNr"
      },
      "id": "fEmLIPc-4LNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие места в получаемом списке занимает реальный состав оборудования, если рассматривать только турбогенераторы"
      ],
      "metadata": {
        "id": "OPMc5g2NwPX4"
      },
      "id": "OPMc5g2NwPX4"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series([r[\"actual_opt_tg_position\"] for r in results]).value_counts().plot(kind='bar');"
      ],
      "metadata": {
        "id": "JUu8KkSyJ9gp"
      },
      "id": "JUu8KkSyJ9gp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие места в получаемом списке занимает реальный состав оборудования, если рассматривать все основное оборудование"
      ],
      "metadata": {
        "id": "C3ctMFSWwYTj"
      },
      "id": "C3ctMFSWwYTj"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series([r[\"actual_opt_position\"] for r in results]).value_counts().plot(kind='bar');"
      ],
      "metadata": {
        "id": "AKn9lX0nALhr"
      },
      "id": "AKn9lX0nALhr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VBnUtJtDBOz1"
      },
      "id": "VBnUtJtDBOz1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GS6hEhDI0ks"
      },
      "id": "6GS6hEhDI0ks",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wxz0JlSZWrvg",
      "metadata": {
        "id": "wxz0JlSZWrvg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}