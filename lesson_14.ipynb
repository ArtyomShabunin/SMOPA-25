{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTiGG3QHKJeIqJmb6COX1P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtyomShabunin/SMOPA-25/blob/main/lesson_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://prana-system.com/files/110/rds_color_full.png\" alt=\"tot image\" width=\"300\"  align=\"center\"/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img src=\"https://mpei.ru/AboutUniverse/OficialInfo/Attributes/PublishingImages/logo1.jpg\" alt=\"mpei image\" width=\"200\" align=\"center\"/>\n",
        "<img src=\"https://mpei.ru/Structure/Universe/tanpe/structure/tfhe/PublishingImages/tot.png\" alt=\"tot image\" width=\"100\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "# **Системы машинного обучения и предиктивной аналитики в тепловой и возобновляемой энергетике**  \n",
        "\n",
        "# ***Практические занятия***\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TyEwg2AMD0e_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Занятие №14\n",
        "# Разбор задач\n",
        "# Глубокое обучение, pytorch\n",
        "**21 мая 2025г.**"
      ],
      "metadata": {
        "id": "BK6wpY7lD6JF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Поиск аномальных данных"
      ],
      "metadata": {
        "id": "gaEVWREJddnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №1\n",
        "#### Условие\n",
        "\n",
        "Необходимо определить, когда установка работает в ненормальном режиме, используя параметры:\n",
        "\n",
        "* Давление за компрессором\n",
        "* Температура выхлопных газов\n",
        "* Температура окружающей среды\n",
        "\n",
        "Задачу решить с использованием модели автокодировщика с размером латентного пространста 2, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "XQ3AckibfQ4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "np.random.seed(0)\n",
        "N_normal = 950\n",
        "N_anomalous = 50\n",
        "\n",
        "# Нормальные данные\n",
        "P_comp = np.random.normal(10, 1, N_normal)\n",
        "T_exhaust = 500 + 20 * (P_comp - 10) + np.random.normal(0, 5, N_normal)\n",
        "T_ambient = np.random.normal(15, 3, N_normal)\n",
        "\n",
        "# Аномалии\n",
        "P_comp_anom = np.random.normal(6, 0.5, N_anomalous)\n",
        "T_exhaust_anom = np.random.normal(700, 20, N_anomalous)  # перегрев\n",
        "T_ambient_anom = np.random.normal(25, 2, N_anomalous)\n",
        "\n",
        "# Объединение\n",
        "X_normal = np.stack([P_comp, T_exhaust, T_ambient], axis=1)\n",
        "X_anomalous = np.stack([P_comp_anom, T_exhaust_anom, T_ambient_anom], axis=1)\n",
        "X_all = np.vstack([X_normal, X_anomalous])\n",
        "y_all = np.array([0]*N_normal + [1]*N_anomalous)  # метки: 0 - норма, 1 - аномалия"
      ],
      "metadata": {
        "id": "cuNL3RtpdmK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "F8_erpt5gdvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_all)\n",
        "\n",
        "# === Разделение ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_all, test_size=0.3, random_state=42)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_train_tensor = ...  # обучаемся только на норме\n",
        "X_test_tensor = ..."
      ],
      "metadata": {
        "id": "ISPjApokgdDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Автокодировщик ===\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)\n",
        "\n",
        "model = Autoencoder()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = ...\n",
        "\n",
        "# === Обучение ===\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    output = ...\n",
        "    loss = ...\n",
        "    ...\n",
        "    ...\n",
        "    ...\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "WIHmbreVlxCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Вычисление ошибки восстановления ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructed = ...\n",
        "    loss_per_sample = ...\n",
        "\n",
        "# === Порог аномалии ===\n",
        "threshold = np.percentile(loss_per_sample, 95)  # верхние 5% — потенциальные аномалии\n",
        "predicted_anomaly = ...\n",
        "\n",
        "# === Визуализация ===\n",
        "# Цвета точек: синие — нормальные, красные — аномалии\n",
        "colors = ['red' if y == 1 else 'blue' for y in y_test]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(range(len(loss_per_sample)), loss_per_sample,\n",
        "            c=colors, alpha=0.6, label='Samples')\n",
        "plt.axhline(threshold, color='black', linestyle='--', label='Threshold')\n",
        "\n",
        "# Легенда\n",
        "normal_patch = mpatches.Patch(color='blue', label='Норма')\n",
        "anomaly_patch = mpatches.Patch(color='red', label='Аномалия')\n",
        "threshold_line = mpatches.Patch(color='black', label='Порог')\n",
        "\n",
        "plt.legend(handles=[normal_patch, anomaly_patch, threshold_line])\n",
        "plt.title(\"Ошибка реконструкции\")\n",
        "plt.xlabel(\"Индекс\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Метрики\n",
        "precision = ...\n",
        "recall = ...\n",
        "f1 = ...\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "id": "k8h-CTmclnnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №2\n",
        "#### Условие\n",
        "\n",
        "Каждое наблюдение — это почасовой профиль потребления электроэнергии за сутки (24 значения).\n",
        "Аномальные профили:\n",
        "\n",
        "* Случайные всплески в ночное время\n",
        "* Слишком ровный или хаотичный график\n",
        "\n",
        "Решить задачу поиска аномалий с использованием модели автокодировщика с размером латентного пространства 3, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "y9yHJHuq1oBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "np.random.seed(0)\n",
        "N_normal = 1000\n",
        "N_anomaly = 100\n",
        "\n",
        "# Нормальные профили: пик утром и вечером\n",
        "def generate_normal():\n",
        "    x = np.linspace(0, 2*np.pi, 24)\n",
        "    profile = 2 + np.sin(x - np.pi/2) + 0.3 * np.random.randn(24)\n",
        "    return profile\n",
        "\n",
        "# Аномальные: шум или всплески ночью\n",
        "def generate_anomaly():\n",
        "    profile = np.random.normal(2, 0.3, 24)\n",
        "    if np.random.rand() > 0.5:\n",
        "        profile[0:6] += np.random.uniform(2, 4)  # ночной всплеск\n",
        "    return profile\n",
        "\n",
        "X_normal = np.array([generate_normal() for _ in range(N_normal)])\n",
        "X_anomalous = np.array([generate_anomaly() for _ in range(N_anomaly)])\n",
        "X_all = np.vstack([X_normal, X_anomalous])\n",
        "y_all = np.array([0]*N_normal + [1]*N_anomaly)"
      ],
      "metadata": {
        "id": "KtI0W-0yhgyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "ox1OLaTK4yGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_all)\n",
        "\n",
        "# === Разделение ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_all, test_size=0.3, random_state=42)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_train_tensor = ...  # обучаемся только на норме\n",
        "X_test_tensor = ..."
      ],
      "metadata": {
        "id": "Cha_0z9Y4yRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Автокодировщик ===\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            ...\n",
        "            )\n",
        "        self.decoder = nn.Sequential(\n",
        "            ...\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return ...\n",
        "\n",
        "model = Autoencoder()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = ...\n",
        "\n",
        "# === Обучение ===\n",
        "for epoch in range(100):\n",
        "    ...\n",
        "    output = ...\n",
        "    loss = ...\n",
        "    ...\n",
        "    ...\n",
        "    ...\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "qZeqK5nul9hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Аномалия-оценка ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    recon = ...\n",
        "    loss_per_sample = ...\n",
        "\n",
        "threshold = np.percentile(loss_per_sample, 95)\n",
        "predicted_anomaly = ...\n",
        "\n",
        "# === Визуализация ===\n",
        "colors = ['red' if y == 1 else 'blue' for y in y_test]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(range(len(loss_per_sample)), loss_per_sample, c=colors, alpha=0.6)\n",
        "plt.axhline(threshold, color='black', linestyle='--', label='Threshold')\n",
        "plt.legend(handles=[\n",
        "    mpatches.Patch(color='blue', label='Норма'),\n",
        "    mpatches.Patch(color='red', label='Аномалия'),\n",
        "    mpatches.Patch(color='black', label='Порог')\n",
        "])\n",
        "plt.title(\"Ошибка реконструкции\")\n",
        "plt.xlabel(\"Индекс\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Метрики\n",
        "precision = ...\n",
        "recall = ...\n",
        "f1 = ...\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "id": "Bd5NwM5ll63m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №3\n",
        "#### Условие\n",
        "\n",
        "Есть архив показаний 5 датчиков:\n",
        "\n",
        "* Температура\n",
        "* Вибрация\n",
        "* Давление\n",
        "* Сила тока\n",
        "* Напряжение\n",
        "\n",
        "Архив содержит следующие аномалии:\n",
        "\n",
        "* Всплески в 1-2 параметрах\n",
        "* Нестабильная работа (скачки)\n",
        "\n",
        "Решить задачу поиска аномалий с использованием модели автокодировщика с размером латентного пространста 2, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "D1FlIpI64yxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "def generate_normal_sensor():\n",
        "    temp = np.random.normal(70, 2)\n",
        "    vib = np.random.normal(0.02, 0.005)\n",
        "    pres = np.random.normal(5, 0.3)\n",
        "    current = np.random.normal(10, 1)\n",
        "    voltage = np.random.normal(220, 3)\n",
        "    return [temp, vib, pres, current, voltage]\n",
        "\n",
        "def generate_anomaly_sensor():\n",
        "    normal = generate_normal_sensor()\n",
        "    i = np.random.choice(len(normal), size=np.random.randint(1, 3), replace=False)\n",
        "    for idx in i:\n",
        "        normal[idx] += np.random.uniform(5, 50)  # сильное отклонение\n",
        "    return normal\n",
        "\n",
        "N_normal = 1200\n",
        "N_anomaly = 100\n",
        "\n",
        "X_normal = np.array([generate_normal_sensor() for _ in range(N_normal)])\n",
        "X_anomalous = np.array([generate_anomaly_sensor() for _ in range(N_anomaly)])\n",
        "X_all = np.vstack([X_normal, X_anomalous])\n",
        "y_all = np.array([0]*N_normal + [1]*N_anomaly)"
      ],
      "metadata": {
        "id": "-oY4R9D19RFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "WJUB_rWl9RWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_all)\n",
        "\n",
        "# === Разделение ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_all, test_size=0.3, random_state=42)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_train_tensor = ...\n",
        "X_test_tensor = ..."
      ],
      "metadata": {
        "id": "7Z2_VHum9RgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class SensorAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = ...\n",
        "        self.decoder = ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        return ...\n",
        "\n",
        "model = SensorAutoencoder()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = ...\n",
        "\n",
        "# === Обучение ===\n",
        "for epoch in range(100):\n",
        "    ...\n",
        "    out = ...\n",
        "    loss = ...\n",
        "    ...\n",
        "    ...\n",
        "    ..."
      ],
      "metadata": {
        "id": "DrrlJ_DgmHNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Результаты ===\n",
        "model.eval()\n",
        "with ...:\n",
        "    recon = ...\n",
        "    loss_per_sample = ...\n",
        "\n",
        "threshold = np.percentile(loss_per_sample, 95)\n",
        "predicted_anomaly = (loss_per_sample > threshold).astype(int)\n",
        "\n",
        "# === Визуализация ===\n",
        "colors = ['red' if y == 1 else 'blue' for y in y_test]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(range(len(loss_per_sample)), loss_per_sample, c=colors, alpha=0.6)\n",
        "plt.axhline(threshold, color='black', linestyle='--')\n",
        "plt.legend(handles=[\n",
        "    mpatches.Patch(color='blue', label='Норма'),\n",
        "    mpatches.Patch(color='red', label='Аномалия'),\n",
        "    mpatches.Patch(color='black', label='Порог')\n",
        "])\n",
        "plt.title(\"Ошибка реконструкции\")\n",
        "plt.xlabel(\"Индекс\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Метрики\n",
        "precision = ...\n",
        "recall = ...\n",
        "f1 = ...\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "id": "L3GOfXegmDwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регрессия"
      ],
      "metadata": {
        "id": "EDk4wB2YKFoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №4\n",
        "#### Условие\n",
        "Предсказать температуру выхлопных газов газотурбинной установки на следующем временном шаге по:\n",
        "\n",
        "* Положению топливного клапана\n",
        "* Температуре окружающей среды\n",
        "* Температуре за компрессором\n",
        "* Давлению за компрессором\n",
        "\n",
        "Задачу решить с помощью модели искусственной нейронной сети, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "lzwBHOuDEDzu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtRSe1zXDlAZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация синтетических данных ===\n",
        "np.random.seed(0)\n",
        "N = 1000\n",
        "\n",
        "fuel_valve = np.random.uniform(0.2, 1.0, size=N)                # положение клапана\n",
        "ambient_temp = np.random.normal(15, 5, size=N)                  # наружная температура\n",
        "T_comp_out = 300 + 100 * fuel_valve + np.random.normal(0, 5, N) # T после компрессора\n",
        "P_comp_out = 5 + 10 * fuel_valve + np.random.normal(0, 1, N)    # P после компрессора\n",
        "\n",
        "# Целевая переменная: температура выхлопных газов\n",
        "T_exhaust = (\n",
        "    500 + 80 * fuel_valve - 0.5 * ambient_temp + 0.1 * T_comp_out\n",
        "    + 2 * P_comp_out + np.random.normal(0, 5, N)\n",
        ")\n",
        "\n",
        "X = np.stack([fuel_valve, ambient_temp, T_comp_out, P_comp_out], axis=1)\n",
        "y = T_exhaust"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "uwHo2YIJHg-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y[:,np.newaxis])\n",
        "\n",
        "# === Разделение на train/test ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_train_tensor = ...\n",
        "y_train_tensor = ...\n",
        "X_test_tensor = ...\n",
        "y_test_tensor = ..."
      ],
      "metadata": {
        "id": "6cL0sdoMDyP5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = Regressor()\n",
        "criterion = ...\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# === Обучение ===\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    ...\n",
        "    output = ...\n",
        "    loss = ...\n",
        "    ...\n",
        "    ...\n",
        "    ...\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "_UAS2XqOmOHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказания и обратная стандартизация ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = ...\n",
        "    y_pred = ...\n",
        "    y_true = ...\n",
        "\n",
        "# === График ===\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(y_true, label='Истина')\n",
        "plt.plot(y_pred, label='Предсказание')\n",
        "plt.legend()\n",
        "plt.title('Прогноз температуры выхлопных газов')\n",
        "plt.xlabel('Индекс')\n",
        "plt.ylabel('Температура выхлопных газов')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Расчет метрики R2\n",
        "r2 = r2_score(y_pred, y_true)\n",
        "print(f\"R² score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "qoCqymjvmL1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №5\n",
        "#### Условие\n",
        "Необходимо спрогнозировать электрическую мощность газотурбинной установки (ГТУ) на основе:\n",
        "\n",
        "* Давления за компрессором `P_comp_out`\n",
        "* Температуры окружающего воздуха `T_ambient`\n",
        "* Уровня подачи топлива `fuel_rate`\n",
        "\n",
        "Задачу решить с помощью модели искусственной нейронной сети, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "hthHMPjzKOJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "np.random.seed(1)\n",
        "N = 1200\n",
        "\n",
        "P_comp_out = np.random.normal(8.0, 1.0, size=N)                   # Давление за компрессором (бар)\n",
        "T_ambient = np.random.normal(20, 6, size=N)                       # Температура воздуха (°C)\n",
        "fuel_rate = np.random.uniform(0.3, 1.0, size=N)                   # Доля открытия топливной подачи (0-1)\n",
        "\n",
        "# Целевая переменная: электрическая мощность (МВт)\n",
        "power_output = (\n",
        "    30 * fuel_rate + 5 * P_comp_out - 0.4 * T_ambient\n",
        "    + np.random.normal(0, 2, size=N)\n",
        ")\n",
        "\n",
        "X = np.stack([P_comp_out, T_ambient, fuel_rate], axis=1)\n",
        "y = power_output"
      ],
      "metadata": {
        "id": "3GaCr1XZDyW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "WE7hPtNiR0FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# === Train/Test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=1)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_train_tensor = ...\n",
        "y_train_tensor = ...\n",
        "X_test_tensor = ...\n",
        "y_test_tensor = ..."
      ],
      "metadata": {
        "id": "5ljYou0eDybQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class PowerRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = ...\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = ...\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = ...\n",
        "\n",
        "# === Обучение ===\n",
        "for epoch in range(150):\n",
        "    ...\n",
        "    y_pred = ...\n",
        "    loss = ...\n",
        "    ...\n",
        "    ...\n",
        "    ...\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "lAF-Ago1n0Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказания ===\n",
        "...\n",
        "with torch.no_grad():\n",
        "    y_pred_test = ...\n",
        "    y_pred_test_inv = ...\n",
        "    y_true_test_inv = ...\n",
        "\n",
        "# === Визуализация ===\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(y_true_test_inv, label='Истина')\n",
        "plt.plot(y_pred_test_inv, label='Предсказание')\n",
        "plt.legend()\n",
        "plt.title(\"Прогноз мощности ГТУ\")\n",
        "plt.xlabel(\"Индекс\")\n",
        "plt.ylabel(\"Мощность, МВт\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Расчет метрики R2\n",
        "r2 = r2_score(y_pred_test_inv, y_true_test_inv)\n",
        "print(f\"R² score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "5E6Zg7qbnxkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №6\n",
        "#### Условие\n",
        "\n",
        "С течением времени КПД ГТУ деградирует из-за:\n",
        "\n",
        "* Наработки (в часах)\n",
        "* Загрязнения фильтров (0–1)\n",
        "* Температуры окружающей среды\n",
        "\n",
        "Нужно построить модель для прогнозирования текущего КПД установки.  \n",
        "Задачу решить с помощью модели искусственной нейронной сети, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "cwsYWJPac3u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "np.random.seed(2)\n",
        "N = 1500\n",
        "\n",
        "hours_run = np.random.uniform(0, 30000, size=N)                   # Наработка (часы)\n",
        "filter_dirtiness = np.clip(np.random.beta(2, 5, size=N), 0, 1)    # Степень загрязнения\n",
        "T_ambient = np.random.normal(18, 5, size=N)                       # Температура воздуха\n",
        "\n",
        "# КПД (%)\n",
        "efficiency = (\n",
        "    42 - 0.0003 * hours_run - 2 * filter_dirtiness - 0.05 * T_ambient\n",
        "    + np.random.normal(0, 0.5, size=N)\n",
        ")\n",
        "\n",
        "X = np.stack([hours_run, filter_dirtiness, T_ambient], axis=1)\n",
        "y = efficiency"
      ],
      "metadata": {
        "id": "E3Otv5l1cyui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "86S3pav2dNJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# === Train/Test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_train_tensor = ...\n",
        "y_train_tensor = ...\n",
        "X_test_tensor = ...\n",
        "y_test_tensor = ..."
      ],
      "metadata": {
        "id": "98IHHU-kdNV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class EfficiencyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = ...\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = ...\n",
        "optimizer = ...\n",
        "criterion = ...\n",
        "\n",
        "# === Обучение ===\n",
        "for epoch in range(200):\n",
        "    ...\n",
        "    y_pred = ...\n",
        "    loss = ...\n",
        "    ...\n",
        "    ...\n",
        "    ...\n",
        "    if epoch % 25 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "_rmoCbmin7Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказания ===\n",
        "model.eval()\n",
        "with ...:\n",
        "    y_pred_test = ...\n",
        "    y_pred_test_inv = ...\n",
        "    y_true_test_inv = ...\n",
        "\n",
        "# === Визуализация ===\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(y_true_test_inv, label='Истина')\n",
        "plt.plot(y_pred_test_inv, label='Предсказание')\n",
        "plt.legend()\n",
        "plt.title(\"Прогноз КПД ГТУ\")\n",
        "plt.xlabel(\"Индекс\")\n",
        "plt.ylabel(\"КПД (%)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Расчет метрики R2\n",
        "r2 = r2_score(y_pred_test_inv, y_true_test_inv)\n",
        "print(f\"R² score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "VfjA9_2fn340"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Прогнозирование временных рядов"
      ],
      "metadata": {
        "id": "baRsVdoK-ya8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №7\n",
        "#### Условие\n",
        "\n",
        "Входные данные (на каждый час):\n",
        "\n",
        "* Историческое потребление (на 24 часа назад)\n",
        "* Время суток (от 0 до 23, как синус и косинус)\n",
        "* День недели (0–6, как синус и косинус)\n",
        "\n",
        "Цель:\n",
        "Предсказать потребление на следующий час.  \n",
        "Задачу решить с помощью модели искусственной нейронной сети, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "NvKRfPoPaOgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ==\n",
        "np.random.seed(42)\n",
        "n_hours = 3000\n",
        "\n",
        "# Время: час суток и день недели\n",
        "hour_of_day = np.arange(n_hours) % 24\n",
        "day_of_week = (np.arange(n_hours) // 24) % 7\n",
        "\n",
        "# Потребление: базовое + дневной цикл + влияние дня недели + шум\n",
        "base = 50 + 10 * np.sin(2 * np.pi * hour_of_day / 24)\n",
        "dow_effect = 5 * np.where(day_of_week < 5, 1.0, 0.7)  # рабочие и выходные\n",
        "noise = np.random.normal(0, 2, n_hours)\n",
        "consumption = base * dow_effect + noise  # финальное потребление\n",
        "\n",
        "# Вспомогательная функция: кодировка времени\n",
        "def encode_time(hour, dow):\n",
        "    hour_sin = np.sin(2 * np.pi * hour / 24)\n",
        "    hour_cos = np.cos(2 * np.pi * hour / 24)\n",
        "    dow_sin = np.sin(2 * np.pi * dow / 7)\n",
        "    dow_cos = np.cos(2 * np.pi * dow / 7)\n",
        "    return np.array([hour_sin, hour_cos, dow_sin, dow_cos])  # shape (4,)\n",
        "\n",
        "# Формирование выборки\n",
        "window_size = 24\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(n_hours - window_size - 1):\n",
        "    past_consumption = consumption[i:i+window_size]  # shape (24,)\n",
        "    time_feat = encode_time(hour_of_day[i+window_size], day_of_week[i+window_size])  # shape (4,)\n",
        "    x = np.concatenate([past_consumption, time_feat])  # shape (28,)\n",
        "    X.append(x)\n",
        "    y.append(consumption[i + window_size])  # целевое значение на следующий час\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "yggii5bCalVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "AQgRMAZValfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_x.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_tensor = ...\n",
        "y_tensor = ...\n",
        "\n",
        "# === Разделение на train/test ===\n",
        "split_idx = int(0.8 * len(X_tensor))\n",
        "X_train, X_test = ...\n",
        "y_train, y_test = ...\n",
        "\n",
        "dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = ..."
      ],
      "metadata": {
        "id": "L9Rt8JwvalnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class FCNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = ...\n",
        "\n",
        "\n",
        "# === Обучение ===\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = ...\n",
        "\n",
        "for epoch in range(20):\n",
        "    ...\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in ...:\n",
        "        pred = ...\n",
        "        loss = ...\n",
        "        ...\n",
        "        ...\n",
        "        ...\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "HmABOX4UohtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказание и метрика ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = ...\n",
        "    y_true_scaled = ...\n",
        "\n",
        "    # Обратная стандартизация\n",
        "    y_pred = ...\n",
        "    y_true = ...\n",
        "\n",
        "# R² score\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "print(f\"\\nR² score on test set: {r2:.4f}\")\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(y_true[:100], label=\"Истина\")\n",
        "plt.plot(y_pred[:100], label=\"Предсказание\")\n",
        "plt.title(\"Прогноз потребления офиса на следующий час\")\n",
        "plt.xlabel(\"Время (часы)\")\n",
        "plt.ylabel(\"Потребление\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FbHe8Osoddi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №8\n",
        "#### Условие\n",
        "\n",
        "Смоделируйте и предскажите почасовое потребление электроэнергии жилого дома на следующие 24 часа на основе предыдущих 168 часов (7 суток). Используйте простую RNN (или LSTM). Задачу решить путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "si6ev6vW-xLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "\n",
        "# Параметры генерации\n",
        "np.random.seed(42)\n",
        "n_days = 100\n",
        "hours_per_day = 24\n",
        "total_hours = n_days * hours_per_day\n",
        "\n",
        "# Генерация сезонности и тренда\n",
        "time = np.arange(total_hours)\n",
        "daily_pattern = 2 * np.sin(2 * np.pi * time / 24)  # дневной цикл\n",
        "weekly_pattern = 1.5 * np.sin(2 * np.pi * time / (24 * 7))  # недельный цикл\n",
        "trend = 0.0005 * time  # небольшой рост\n",
        "noise = np.random.normal(0, 0.3, size=total_hours)\n",
        "\n",
        "# Итоговый временной ряд\n",
        "consumption = 5 + daily_pattern + weekly_pattern + trend + noise\n",
        "\n",
        "# Преобразуем в формат [samples, sequence_length]\n",
        "window_size = 168\n",
        "target_size = 24\n",
        "\n",
        "X, y = [], []\n",
        "for i in range(len(consumption) - window_size - target_size):\n",
        "    X.append(consumption[i:i+window_size])\n",
        "    y.append(consumption[i+window_size:i+window_size+target_size])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "9xu7w_Mi-wUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "fBVH4Idw_hbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# === Cтандартизация данных ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.reshape(-1, 1)).reshape(X.shape)\n",
        "y_scaled = scaler.transform(y.reshape(-1, 1)).reshape(y.shape)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_tensor = ...\n",
        "y_tensor = ..."
      ],
      "metadata": {
        "id": "o_P74rgf_ho9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class EnergyLSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=24):\n",
        "        super().__init__()\n",
        "        self.lstm = ...\n",
        "        self.linear = ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]  # берем только последний скрытый вектор\n",
        "        return self.linear(out)\n",
        "\n",
        "model = ...\n",
        "\n",
        "# === Обучение ===\n",
        "dataset = TensorDataset(X_tensor.unsqueeze(-1), y_tensor)\n",
        "loader = ...\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = ...\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_X, batch_y in ...:\n",
        "        pred = ...\n",
        "        loss = ...\n",
        "        ...\n",
        "        ...\n",
        "        ...\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "4_iqWFdfowPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказание ===\n",
        "# Предсказание на последнем фрагменте\n",
        "with torch.no_grad():\n",
        "    test_input = X_tensor[-1].unsqueeze(0).unsqueeze(-1)\n",
        "    pred_scaled = ...\n",
        "    pred = ...\n",
        "\n",
        "plt.plot(np.arange(24), consumption[-24:], label='Истина')\n",
        "plt.plot(np.arange(24), pred.flatten(), label='Предсказание')\n",
        "plt.legend()\n",
        "plt.title(\"Прогноз потребления энергии на 24 часа\")\n",
        "plt.show()\n",
        "\n",
        "# Расчет метрики R2\n",
        "y_true = consumption[-24:]\n",
        "y_pred = pred.flatten()\n",
        "\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "print(f\"R² score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "Vht8RQlHotfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №9\n",
        "#### Условие\n",
        "\n",
        "На основе временных рядов:\n",
        "\n",
        "* `ток` (текущая нагрузка трансформатора, A)\n",
        "* `температура_внешняя` (температура воздуха, °C)\n",
        "\n",
        "Необходимо предсказать:\n",
        "\n",
        "* `температура_трансформатора` через 1 час.\n",
        "\n",
        "Задачу решить с помощью модели искусственной нейронной сети, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "eMxcscRdPTcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "np.random.seed(42)\n",
        "\n",
        "n_hours = 3000  # 125 суток\n",
        "\n",
        "time = np.arange(n_hours)\n",
        "external_temp = 10 + 10 * np.sin(2 * np.pi * time / 24) + np.random.normal(0, 1, n_hours)\n",
        "current = 100 + 40 * np.sin(2 * np.pi * time / 24 + np.pi/4) + np.random.normal(0, 5, n_hours)\n",
        "\n",
        "# Температура трансформатора зависит от тока + внешней температуры + инерция (скользящее среднее)\n",
        "temp_transformer = (\n",
        "    0.5 * current + 0.3 * external_temp +\n",
        "    0.2 * np.convolve(current, np.ones(5)/5, mode='same')\n",
        "    + np.random.normal(0, 1, n_hours)\n",
        ")\n",
        "\n",
        "# Подготовка данных\n",
        "window_size = 24  # используем 24 часа для прогноза на 1 час вперёд\n",
        "\n",
        "X, y = [], []\n",
        "for i in range(n_hours - window_size - 1):\n",
        "    x_window = np.stack([\n",
        "        current[i:i+window_size],\n",
        "        external_temp[i:i+window_size]\n",
        "    ], axis=1)\n",
        "    X.append(x_window)\n",
        "    y.append(temp_transformer[i+window_size])  # предсказание через 1 час\n",
        "\n",
        "X = np.array(X)  # [samples, window, features]\n",
        "y = np.array(y).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "JfKDm5H0BDmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "pBCQ13B9RPle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_reshaped = X.reshape(-1, 2)\n",
        "X_scaled = scaler_x.fit_transform(X_reshaped).reshape(X.shape)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_tensor = ...\n",
        "y_tensor = ...\n",
        "\n",
        "# === Разделение на train/test ===\n",
        "split_idx = int(0.8 * len(X_tensor))\n",
        "X_train, X_test = ...\n",
        "y_train, y_test = ..."
      ],
      "metadata": {
        "id": "nCZ6M16vHYP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class TransformerTempLSTM(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = ...\n",
        "        self.linear = ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]  # последний временной шаг\n",
        "        return self.linear(out)\n",
        "\n",
        "model = ...\n",
        "\n",
        "# === Обучение модели ===\n",
        "dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = ...\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = ...\n",
        "\n",
        "for epoch in range(20):\n",
        "    for batch_x, batch_y in ...:\n",
        "        pred = ...\n",
        "        loss = ...\n",
        "        ...\n",
        "        ...\n",
        "        ...\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "SfioHOzWo3NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказание ===\n",
        "with torch.no_grad():\n",
        "    y_pred_scaled = model(X_test).numpy()\n",
        "    y_true_scaled = y_test.numpy()\n",
        "\n",
        "    # Обратная стандартизация\n",
        "    y_pred = ...\n",
        "    y_true = ...\n",
        "\n",
        "# Метрика\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "print(f\"\\nR² score on test set: {r2:.4f}\")\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(y_true[:100], label='Истина')\n",
        "plt.plot(y_pred[:100], label='предсказание')\n",
        "plt.legend()\n",
        "plt.title(\"Температура трансформатора — 1 час вперёд\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N1pCIbrjo03L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Задача №10\n",
        "#### Условие\n",
        "\n",
        "Даны почасовые данные:\n",
        "\n",
        "* Потребление зданий A, B, C\n",
        "* Температура воздуха (°C)\n",
        "\n",
        "Требуется:\n",
        "\n",
        "* На основе данных за последние 24 часа предсказать **суммарное потребление** в районе через 1 час.\n",
        "\n",
        "Задачу решить с помощью модели искусственной нейронной сети, путем заполнения пропущенных фрагментов кода (...)."
      ],
      "metadata": {
        "id": "I0AgnbKbUhhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# === Генерация данных ===\n",
        "np.random.seed(42)\n",
        "\n",
        "n_hours = 4000\n",
        "\n",
        "time = np.arange(n_hours)\n",
        "\n",
        "# Температура воздуха (дневной цикл + шум)\n",
        "temp_outdoor = 10 + 10 * np.sin(2 * np.pi * time / 24) + np.random.normal(0, 1, n_hours)\n",
        "\n",
        "# Потребление зданий: базовый уровень + зависимость от температуры и времени суток\n",
        "def gen_building_usage(base, temp_weight, noise_level):\n",
        "    usage = (\n",
        "        base\n",
        "        + temp_weight * (20 - temp_outdoor)  # холодно — больше потребление\n",
        "        + 5 * np.sin(2 * np.pi * time / 24)  # дневной цикл\n",
        "        + np.random.normal(0, noise_level, n_hours)\n",
        "    )\n",
        "    return usage\n",
        "\n",
        "A = gen_building_usage(30, 0.8, 2)\n",
        "B = gen_building_usage(40, 1.0, 3)\n",
        "C = gen_building_usage(25, 0.5, 1.5)\n",
        "\n",
        "# Целевая переменная: общее потребление\n",
        "total_usage = A + B + C\n",
        "\n",
        "# Подготовка данных\n",
        "window_size = 24  # 24 часа истории\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(n_hours - window_size - 1):\n",
        "    x_window = np.stack([\n",
        "        A[i:i+window_size],\n",
        "        B[i:i+window_size],\n",
        "        C[i:i+window_size],\n",
        "        temp_outdoor[i:i+window_size]\n",
        "    ], axis=1)\n",
        "    X.append(x_window)\n",
        "    y.append(total_usage[i+window_size])  # на 1 час вперёд\n",
        "\n",
        "X = np.array(X)  # [samples, window_size, features]\n",
        "y = np.array(y).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "CHHM2r2XSfVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение"
      ],
      "metadata": {
        "id": "9ByJyRFbWedB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# === Стандартизация ===\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_x.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# === Преобразование в тензоры ===\n",
        "X_tensor = ...\n",
        "y_tensor = ...\n",
        "\n",
        "# Train/test split\n",
        "split_idx = int(0.8 * len(X_tensor))\n",
        "X_train, X_test = ...\n",
        "y_train, y_test = ..."
      ],
      "metadata": {
        "id": "4-qc3vKHWe3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Модель ===\n",
        "class TimeSeriesTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.regressor = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)  # [B, T, d_model]\n",
        "        x = self.transformer(x)\n",
        "        out = x[:, -1, :]  # последний временной шаг\n",
        "        return self.regressor(out)\n",
        "\n",
        "model = TimeSeriesTransformer(input_dim=4)\n",
        "\n",
        "# === Обучение модели ===\n",
        "dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = ...\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = ...\n",
        "\n",
        "for epoch in range(20):\n",
        "    ...\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        pred = ...\n",
        "        loss = ...\n",
        "        ...\n",
        "        ...\n",
        "        ...\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "cHcGLAfro_Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Предсказание ===\n",
        "...\n",
        "with ...:\n",
        "    y_pred_scaled = ...\n",
        "    y_true_scaled = ...\n",
        "\n",
        "    y_pred = ...\n",
        "    y_true = ...\n",
        "\n",
        "# R² метрика\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "print(f\"\\nR² score on test set: {r2:.4f}\")\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(y_true[:100], label='Истина')\n",
        "plt.plot(y_pred[:100], label='Предсказание')\n",
        "plt.title(\"Суммарное потребление — прогноз на 1 час\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q4YhJZGjXGCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}